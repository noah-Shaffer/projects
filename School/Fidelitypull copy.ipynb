{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab62967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ±Ô∏è  Mouse position (1/sec) - Ctrl+C to quit\n",
      "X: 1147 Y:  326\n",
      "‚úÖ Stopped.\n"
     ]
    }
   ],
   "source": [
    "# cmd shift 5 for area, this code for x_y\n",
    "import pyautogui\n",
    "import time\n",
    "\n",
    "print(\"üñ±Ô∏è  Mouse position (1/sec) - Ctrl+C to quit\")\n",
    "try:\n",
    "    while True:\n",
    "        x, y = pyautogui.position()\n",
    "        print(f\"\\rX: {x:4d} Y: {y:4d}\", end='', flush=True)\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚úÖ Stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77c443d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://deepdoctection-deepdoctection.hf.space ‚úî\n",
      "üöÄ Starting order book monitor (every 2.0s)\n",
      "Table region: (50, 227, 283, 525)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/1bh6mfq97bxdwzwnr49jf8nm0000gn/T/ipykernel_50643/3049008669.py:51: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1] ‚úÖ Snapshot saved | 26 rows ‚Üí flattened to 157 columns\n",
      "üìÅ Appended ‚Üí fidelity_orderbook_log.csv\n",
      "------------------------------------------------------------\n",
      "[1] ‚ö° Processed in 10.73s (faster than interval!)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/1bh6mfq97bxdwzwnr49jf8nm0000gn/T/ipykernel_50643/3049008669.py:51: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2] ‚úÖ Snapshot saved | 26 rows ‚Üí flattened to 157 columns\n",
      "üìÅ Appended ‚Üí fidelity_orderbook_log.csv\n",
      "------------------------------------------------------------\n",
      "[2] ‚ö° Processed in 10.83s (faster than interval!)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/1bh6mfq97bxdwzwnr49jf8nm0000gn/T/ipykernel_50643/3049008669.py:51: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3] ‚úÖ Snapshot saved | 26 rows ‚Üí flattened to 157 columns\n",
      "üìÅ Appended ‚Üí fidelity_orderbook_log.csv\n",
      "------------------------------------------------------------\n",
      "[3] ‚ö° Processed in 10.80s (faster than interval!)\n",
      "\n",
      "üõë Stopped by user\n",
      "üìä Completed 4 iterations\n"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n",
    "from gradio_client import Client, handle_file\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# CONFIGURATION\n",
    "TABLE_X, TABLE_Y, TABLE_WIDTH, TABLE_HEIGHT = 50, 227, 283, 525\n",
    "INTERVAL_SECONDS = 2.0\n",
    "CSV_FILE = \"fidelity_orderbook_log.csv\"\n",
    "\n",
    "# REUSE CLIENT (critical for speed)\n",
    "client = Client(\"deepdoctection/deepdoctection\")\n",
    "\n",
    "print(f\"üöÄ Starting order book monitor (every {INTERVAL_SECONDS}s)\")\n",
    "print(f\"Table region: ({TABLE_X}, {TABLE_Y}, {TABLE_WIDTH}, {TABLE_HEIGHT})\")\n",
    "\n",
    "iteration = 0\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    iteration += 1\n",
    "\n",
    "    try:\n",
    "        # 1. CAPTURE SCREENSHOT\n",
    "        screenshot = pyautogui.screenshot(region=(TABLE_X, TABLE_Y, TABLE_WIDTH, TABLE_HEIGHT))\n",
    "\n",
    "        # 2. PREPROCESS IMAGE\n",
    "        img = screenshot.convert(\"RGB\")\n",
    "        gray = ImageEnhance.Contrast(img.convert(\"L\")).enhance(1.2)\n",
    "        gray = gray.filter(ImageFilter.SHARPEN)\n",
    "        inverted = ImageOps.invert(gray)\n",
    "        binary = inverted.point(lambda p: 0 if p > 140 else 255)\n",
    "        binary.save(\"processed_table_region.png\")\n",
    "\n",
    "        # 3. OCR VIA DEEPDOCTECTION\n",
    "        result = client.predict(\n",
    "            img=handle_file(\"processed_table_region.png\"),\n",
    "            pdf=None,\n",
    "            max_datapoints=1,\n",
    "            api_name=\"/analyze_image\",\n",
    "        )\n",
    "\n",
    "        # 4. PARSE TABLE\n",
    "        if isinstance(result, tuple) and len(result) >= 4:\n",
    "            html_table = result[3]\n",
    "            soup = BeautifulSoup(html_table, \"html.parser\")\n",
    "            table = soup.find(\"table\")\n",
    "            df = pd.read_html(str(table))[0]\n",
    "\n",
    "            # Ensure readable string headers (handle blanks)\n",
    "            if df.columns.isnull().any():\n",
    "                df.columns = [f\"col_{i}\" if pd.isna(c) else str(c).strip() for i, c in enumerate(df.columns)]\n",
    "            else:\n",
    "                df.columns = [str(c).strip() for c in df.columns]\n",
    "\n",
    "            # 5. FLATTEN INTO SINGLE ROW SAFELY\n",
    "            flat_values = df.to_numpy().ravel()\n",
    "            col_labels = []\n",
    "            for i in range(len(df)):\n",
    "                for col in df.columns:\n",
    "                    col_labels.append(f\"{col}_{i+1}\")\n",
    "\n",
    "            # Handle mismatch gracefully\n",
    "            if len(col_labels) != len(flat_values):\n",
    "                min_len = min(len(col_labels), len(flat_values))\n",
    "                col_labels = col_labels[:min_len]\n",
    "                flat_values = flat_values[:min_len]\n",
    "\n",
    "            # 6. BUILD ROW + SAVE (APPEND)\n",
    "            row_data = [datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")] + list(flat_values)\n",
    "            col_names = [\"timestamp\"] + col_labels\n",
    "\n",
    "            single_row = pd.DataFrame([row_data], columns=col_names)\n",
    "\n",
    "            header_needed = not os.path.exists(CSV_FILE)\n",
    "            single_row.to_csv(CSV_FILE, index=False, mode=\"a\", header=header_needed)\n",
    "\n",
    "            print(f\"[{iteration:3d}] ‚úÖ Snapshot saved | {df.shape[0]} rows ‚Üí flattened to {single_row.shape[1]} columns\")\n",
    "            print(f\"üìÅ Appended ‚Üí {CSV_FILE}\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "        else:\n",
    "            print(f\"[{iteration}] ‚ùå No table detected\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nüõë Stopped by user\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"[{iteration}] ‚ùå Error: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Maintain consistent interval\n",
    "    elapsed = time.time() - start_time\n",
    "    sleep_time = max(0, INTERVAL_SECONDS - elapsed)\n",
    "    if sleep_time > 0:\n",
    "        time.sleep(sleep_time)\n",
    "    else:\n",
    "        print(f\"[{iteration}] ‚ö° Processed in {elapsed:.2f}s (faster than interval!)\")\n",
    "\n",
    "print(f\"üìä Completed {iteration} iterations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d5699d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SHIFTED LEFT (first 20):\n",
      "['timestamp', 'exch_b_1', 'size_b_1', 'bid_1', 'ask_1', 'size_a_1', 'exch_a_1', 'exch_b_2', 'size_b_2', 'bid_2', 'ask_2', 'size_a_2', 'exch_a_2', 'exch_b_3', 'size_b_3', 'bid_3', 'ask_3', 'size_a_3', 'exch_a_3', 'exch_b_4']\n",
      "\n",
      "Sample data:\n",
      "             timestamp exch_b_1  size_b_1   bid_1   ask_1  size_a_1 exch_a_1\n",
      "0  2025-12-06 09:33:24     ARCX         1  454.61  454.64       160     XNMS\n",
      "1  2025-12-06 09:33:35     ARCX         1  454.61  454.64       160     XNMS\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV\n",
    "df = pd.read_csv(\"fidelity_orderbook_log.csv\")\n",
    "\n",
    "# ALTERNATING HEADERS for bid/ask sides\n",
    "BID_HEADERS = ['exch_b', 'size_b', 'bid', 'ask', 'size_a', 'exch_a']\n",
    "\n",
    "# Keep timestamp + data columns (skip first 6 junk header columns)\n",
    "data_columns = df.columns[6:]\n",
    "df_data = df[['timestamp'] + list(data_columns)].copy()\n",
    "\n",
    "# SHIFT LEFT: Remove first junk column and shift all data left by 1\n",
    "first_junk_col = data_columns[0]\n",
    "df_data = df_data.drop(columns=[first_junk_col])  # Drop first junk column\n",
    "\n",
    "# Create PROPER alternating column names (now 1 less column)\n",
    "col_names = [\"timestamp\"]\n",
    "level = 1\n",
    "\n",
    "for i in range(len(df_data.columns) - 1):  # Adjusted for dropped column\n",
    "    base_header = BID_HEADERS[i % 6]\n",
    "    col_names.append(f\"{base_header}_{level}\")\n",
    "    \n",
    "    if (i + 1) % 6 == 0:\n",
    "        level += 1\n",
    "\n",
    "# Assign the alternating column names\n",
    "df_data.columns = col_names\n",
    "\n",
    "# Save cleaned version\n",
    "df_data.to_csv(\"fidelity_orderbook_clean.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ SHIFTED LEFT (first 20):\")\n",
    "print(list(df_data.columns[:20]))\n",
    "print(\"\\nSample data:\")\n",
    "print(df_data[['timestamp', 'exch_b_1', 'size_b_1', 'bid_1', 'ask_1', 'size_a_1', 'exch_a_1']].head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37090d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>exch_b_1</th>\n",
       "      <th>size_b_1</th>\n",
       "      <th>bid_1</th>\n",
       "      <th>ask_1</th>\n",
       "      <th>size_a_1</th>\n",
       "      <th>exch_a_1</th>\n",
       "      <th>exch_b_2</th>\n",
       "      <th>size_b_2</th>\n",
       "      <th>bid_2</th>\n",
       "      <th>...</th>\n",
       "      <th>bid_24</th>\n",
       "      <th>ask_24</th>\n",
       "      <th>size_a_24</th>\n",
       "      <th>exch_a_24</th>\n",
       "      <th>exch_b_25</th>\n",
       "      <th>size_b_25</th>\n",
       "      <th>bid_25</th>\n",
       "      <th>ask_25</th>\n",
       "      <th>size_a_25</th>\n",
       "      <th>exch_a_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-12-06 09:33:24</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>454.61</td>\n",
       "      <td>454.64</td>\n",
       "      <td>160</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>80</td>\n",
       "      <td>454.68</td>\n",
       "      <td>...</td>\n",
       "      <td>453.42</td>\n",
       "      <td>455.09</td>\n",
       "      <td>460</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>453.31</td>\n",
       "      <td>455.1</td>\n",
       "      <td>316</td>\n",
       "      <td>ARCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-12-06 09:33:35</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>454.61</td>\n",
       "      <td>454.64</td>\n",
       "      <td>160</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>80</td>\n",
       "      <td>454.68</td>\n",
       "      <td>...</td>\n",
       "      <td>453.42</td>\n",
       "      <td>455.09</td>\n",
       "      <td>460</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>453.31</td>\n",
       "      <td>455.1</td>\n",
       "      <td>316</td>\n",
       "      <td>ARCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-06 09:33:46</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>454.61</td>\n",
       "      <td>454.64</td>\n",
       "      <td>160</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>80</td>\n",
       "      <td>454.68</td>\n",
       "      <td>...</td>\n",
       "      <td>453.42</td>\n",
       "      <td>455.09</td>\n",
       "      <td>460</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>453.31</td>\n",
       "      <td>455.1</td>\n",
       "      <td>316</td>\n",
       "      <td>ARCX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp exch_b_1  size_b_1   bid_1   ask_1  size_a_1 exch_a_1  \\\n",
       "0  2025-12-06 09:33:24     ARCX         1  454.61  454.64       160     XNMS   \n",
       "1  2025-12-06 09:33:35     ARCX         1  454.61  454.64       160     XNMS   \n",
       "2  2025-12-06 09:33:46     ARCX         1  454.61  454.64       160     XNMS   \n",
       "\n",
       "  exch_b_2  size_b_2   bid_2  ...  bid_24  ask_24 size_a_24 exch_a_24  \\\n",
       "0     XNMS        80  454.68  ...  453.42  455.09       460      ARCX   \n",
       "1     XNMS        80  454.68  ...  453.42  455.09       460      ARCX   \n",
       "2     XNMS        80  454.68  ...  453.42  455.09       460      ARCX   \n",
       "\n",
       "   exch_b_25  size_b_25  bid_25  ask_25 size_a_25 exch_a_25  \n",
       "0       ARCX          1  453.31   455.1       316      ARCX  \n",
       "1       ARCX          1  453.31   455.1       316      ARCX  \n",
       "2       ARCX          1  453.31   455.1       316      ARCX  \n",
       "\n",
       "[3 rows x 151 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db157dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://deepdoctection-deepdoctection.hf.space ‚úî\n",
      "üöÄ Starting order book monitor (every 2.0s)\n",
      "Table region: (50, 227, 283, 525)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/1bh6mfq97bxdwzwnr49jf8nm0000gn/T/ipykernel_50643/3363499120.py:53: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1] ‚úÖ Snapshot saved | 26 rows ‚Üí flattened to 157 columns\n",
      "üìÅ Appended ‚Üí fidelity_orderbook_log.csv\n",
      "------------------------------------------------------------\n",
      "[1] ‚ö° Processed in 11.83s (faster than interval!)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/1bh6mfq97bxdwzwnr49jf8nm0000gn/T/ipykernel_50643/3363499120.py:53: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2] ‚úÖ Snapshot saved | 26 rows ‚Üí flattened to 157 columns\n",
      "üìÅ Appended ‚Üí fidelity_orderbook_log.csv\n",
      "------------------------------------------------------------\n",
      "[2] ‚ö° Processed in 11.33s (faster than interval!)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/1bh6mfq97bxdwzwnr49jf8nm0000gn/T/ipykernel_50643/3363499120.py:53: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3] ‚úÖ Snapshot saved | 26 rows ‚Üí flattened to 157 columns\n",
      "üìÅ Appended ‚Üí fidelity_orderbook_log.csv\n",
      "------------------------------------------------------------\n",
      "[3] ‚ö° Processed in 10.95s (faster than interval!)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/1bh6mfq97bxdwzwnr49jf8nm0000gn/T/ipykernel_50643/3363499120.py:53: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4] ‚úÖ Snapshot saved | 26 rows ‚Üí flattened to 157 columns\n",
      "üìÅ Appended ‚Üí fidelity_orderbook_log.csv\n",
      "------------------------------------------------------------\n",
      "[4] ‚ö° Processed in 10.97s (faster than interval!)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/1bh6mfq97bxdwzwnr49jf8nm0000gn/T/ipykernel_50643/3363499120.py:53: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5] ‚úÖ Snapshot saved | 26 rows ‚Üí flattened to 157 columns\n",
      "üìÅ Appended ‚Üí fidelity_orderbook_log.csv\n",
      "------------------------------------------------------------\n",
      "[5] ‚ö° Processed in 11.48s (faster than interval!)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/1bh6mfq97bxdwzwnr49jf8nm0000gn/T/ipykernel_50643/3363499120.py:53: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6] ‚úÖ Snapshot saved | 26 rows ‚Üí flattened to 157 columns\n",
      "üìÅ Appended ‚Üí fidelity_orderbook_log.csv\n",
      "------------------------------------------------------------\n",
      "[6] ‚ö° Processed in 11.26s (faster than interval!)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/1bh6mfq97bxdwzwnr49jf8nm0000gn/T/ipykernel_50643/3363499120.py:53: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7] ‚úÖ Snapshot saved | 26 rows ‚Üí flattened to 157 columns\n",
      "üìÅ Appended ‚Üí fidelity_orderbook_log.csv\n",
      "------------------------------------------------------------\n",
      "[7] ‚ö° Processed in 10.75s (faster than interval!)\n",
      "\n",
      "üõë Stopped by user ‚Äî starting CSV cleanup...\n",
      "‚úÖ Cleaned CSV saved ‚Üí fidelity_orderbook_clean.csv\n",
      "First 20 columns:\n",
      "['timestamp', 'exch_b_1', 'size_b_1', 'bid_1', 'ask_1', 'size_a_1', 'exch_a_1', 'exch_b_2', 'size_b_2', 'bid_2', 'ask_2', 'size_a_2', 'exch_a_2', 'exch_b_3', 'size_b_3', 'bid_3', 'ask_3', 'size_a_3', 'exch_a_3', 'exch_b_4']\n",
      "\n",
      "Sample preview:\n",
      "             timestamp exch_b_1  size_b_1   bid_1   ask_1  size_a_1 exch_a_1\n",
      "0  2025-12-06 09:35:31     ARCX         1  454.61  454.64       160     XNMS\n",
      "1  2025-12-06 09:35:42     ARCX         1  454.61  454.64       160     XNMS\n"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n",
    "from gradio_client import Client, handle_file\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# CONFIGURATION\n",
    "TABLE_X, TABLE_Y, TABLE_WIDTH, TABLE_HEIGHT = 50, 227, 283, 525\n",
    "INTERVAL_SECONDS = 2.0\n",
    "CSV_FILE = \"fidelity_orderbook_log.csv\"\n",
    "CLEAN_CSV_FILE = \"fidelity_orderbook_clean.csv\"\n",
    "\n",
    "# REUSE CLIENT (critical for speed)\n",
    "client = Client(\"deepdoctection/deepdoctection\")\n",
    "\n",
    "print(f\"üöÄ Starting order book monitor (every {INTERVAL_SECONDS}s)\")\n",
    "print(f\"Table region: ({TABLE_X}, {TABLE_Y}, {TABLE_WIDTH}, {TABLE_HEIGHT})\")\n",
    "\n",
    "iteration = 0\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        iteration += 1\n",
    "\n",
    "        try:\n",
    "            # 1. CAPTURE SCREENSHOT\n",
    "            screenshot = pyautogui.screenshot(region=(TABLE_X, TABLE_Y, TABLE_WIDTH, TABLE_HEIGHT))\n",
    "\n",
    "            # 2. PREPROCESS IMAGE\n",
    "            img = screenshot.convert(\"RGB\")\n",
    "            gray = ImageEnhance.Contrast(img.convert(\"L\")).enhance(1.2)\n",
    "            gray = gray.filter(ImageFilter.SHARPEN)\n",
    "            inverted = ImageOps.invert(gray)\n",
    "            binary = inverted.point(lambda p: 0 if p > 140 else 255)\n",
    "            binary.save(\"processed_table_region.png\")\n",
    "\n",
    "            # 3. OCR VIA DEEPDOCTECTION\n",
    "            result = client.predict(\n",
    "                img=handle_file(\"processed_table_region.png\"),\n",
    "                pdf=None,\n",
    "                max_datapoints=1,\n",
    "                api_name=\"/analyze_image\",\n",
    "            )\n",
    "\n",
    "            # 4. PARSE TABLE\n",
    "            if isinstance(result, tuple) and len(result) >= 4:\n",
    "                html_table = result[3]\n",
    "                soup = BeautifulSoup(html_table, \"html.parser\")\n",
    "                table = soup.find(\"table\")\n",
    "                df = pd.read_html(str(table))[0]\n",
    "\n",
    "                if df.columns.isnull().any():\n",
    "                    df.columns = [f\"col_{i}\" if pd.isna(c) else str(c).strip() for i, c in enumerate(df.columns)]\n",
    "                else:\n",
    "                    df.columns = [str(c).strip() for c in df.columns]\n",
    "\n",
    "                flat_values = df.to_numpy().ravel()\n",
    "                col_labels = []\n",
    "                for i in range(len(df)):\n",
    "                    for col in df.columns:\n",
    "                        col_labels.append(f\"{col}_{i+1}\")\n",
    "\n",
    "                if len(col_labels) != len(flat_values):\n",
    "                    min_len = min(len(col_labels), len(flat_values))\n",
    "                    col_labels = col_labels[:min_len]\n",
    "                    flat_values = flat_values[:min_len]\n",
    "\n",
    "                row_data = [datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")] + list(flat_values)\n",
    "                col_names = [\"timestamp\"] + col_labels\n",
    "\n",
    "                single_row = pd.DataFrame([row_data], columns=col_names)\n",
    "\n",
    "                header_needed = not os.path.exists(CSV_FILE)\n",
    "                single_row.to_csv(CSV_FILE, index=False, mode=\"a\", header=header_needed)\n",
    "\n",
    "                print(f\"[{iteration:3d}]  Snapshot saved | {df.shape[0]} rows ‚Üí flattened to {single_row.shape[1]} columns\")\n",
    "\n",
    "            else:\n",
    "                print(f\"[{iteration}]  No table detected\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[{iteration}]  Error: {e}\")\n",
    "            continue\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        sleep_time = max(0, INTERVAL_SECONDS - elapsed)\n",
    "        if sleep_time > 0:\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n Stopped by user ‚Äî starting CSV cleanup...\")\n",
    "\n",
    "# ===============================\n",
    "# CLEANUP AND REFORMAT STORED CSV\n",
    "# ===============================\n",
    "if os.path.exists(CSV_FILE):\n",
    "    df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "    BID_HEADERS = ['exch_b', 'size_b', 'bid', 'ask', 'size_a', 'exch_a']\n",
    "\n",
    "    # Keep timestamp + data columns (skip first 6 junk header columns)\n",
    "    data_columns = df.columns[6:]\n",
    "    df_data = df[['timestamp'] + list(data_columns)].copy()\n",
    "\n",
    "    # Drop first junk column and shift left by one\n",
    "    first_junk_col = data_columns[0]\n",
    "    df_data = df_data.drop(columns=[first_junk_col])\n",
    "\n",
    "    # Create proper alternating column names\n",
    "    col_names = [\"timestamp\"]\n",
    "    level = 1\n",
    "    for i in range(len(df_data.columns) - 1):  # Adjust for dropped column\n",
    "        base_header = BID_HEADERS[i % 6]\n",
    "        col_names.append(f\"{base_header}_{level}\")\n",
    "        if (i + 1) % 6 == 0:\n",
    "            level += 1\n",
    "\n",
    "    df_data.columns = col_names\n",
    "    df_data.to_csv(CLEAN_CSV_FILE, index=False)\n",
    "\n",
    "    print(f\"‚úÖ Cleaned CSV saved ‚Üí {CLEAN_CSV_FILE}\")\n",
    "    print(\"First 20 columns:\")\n",
    "    print(list(df_data.columns[:20]))\n",
    "    print(\"\\nSample preview:\")\n",
    "    print(df_data[['timestamp', 'exch_b_1', 'size_b_1', 'bid_1', 'ask_1', 'size_a_1', 'exch_a_1']].head(2))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No CSV file found; skipping cleanup.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fee5d0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>exch_b_1</th>\n",
       "      <th>size_b_1</th>\n",
       "      <th>bid_1</th>\n",
       "      <th>ask_1</th>\n",
       "      <th>size_a_1</th>\n",
       "      <th>exch_a_1</th>\n",
       "      <th>exch_b_2</th>\n",
       "      <th>size_b_2</th>\n",
       "      <th>bid_2</th>\n",
       "      <th>...</th>\n",
       "      <th>bid_24</th>\n",
       "      <th>ask_24</th>\n",
       "      <th>size_a_24</th>\n",
       "      <th>exch_a_24</th>\n",
       "      <th>exch_b_25</th>\n",
       "      <th>size_b_25</th>\n",
       "      <th>bid_25</th>\n",
       "      <th>ask_25</th>\n",
       "      <th>size_a_25</th>\n",
       "      <th>exch_a_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-12-06 09:35:31</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>454.61</td>\n",
       "      <td>454.64</td>\n",
       "      <td>160</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>80</td>\n",
       "      <td>454.68</td>\n",
       "      <td>...</td>\n",
       "      <td>453.42</td>\n",
       "      <td>455.09</td>\n",
       "      <td>460</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>453.31</td>\n",
       "      <td>455.1</td>\n",
       "      <td>316</td>\n",
       "      <td>ARCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-12-06 09:35:42</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>454.61</td>\n",
       "      <td>454.64</td>\n",
       "      <td>160</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>80</td>\n",
       "      <td>454.68</td>\n",
       "      <td>...</td>\n",
       "      <td>453.42</td>\n",
       "      <td>455.09</td>\n",
       "      <td>460</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>453.31</td>\n",
       "      <td>455.1</td>\n",
       "      <td>316</td>\n",
       "      <td>ARCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-06 09:35:53</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>454.61</td>\n",
       "      <td>454.64</td>\n",
       "      <td>160</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>80</td>\n",
       "      <td>454.68</td>\n",
       "      <td>...</td>\n",
       "      <td>453.42</td>\n",
       "      <td>455.09</td>\n",
       "      <td>460</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>453.31</td>\n",
       "      <td>455.1</td>\n",
       "      <td>316</td>\n",
       "      <td>ARCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-12-06 09:36:03</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>454.61</td>\n",
       "      <td>454.64</td>\n",
       "      <td>160</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>80</td>\n",
       "      <td>454.68</td>\n",
       "      <td>...</td>\n",
       "      <td>453.42</td>\n",
       "      <td>455.09</td>\n",
       "      <td>460</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>453.31</td>\n",
       "      <td>455.1</td>\n",
       "      <td>316</td>\n",
       "      <td>ARCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-12-06 09:37:18</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>454.61</td>\n",
       "      <td>454.64</td>\n",
       "      <td>160</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>80</td>\n",
       "      <td>454.68</td>\n",
       "      <td>...</td>\n",
       "      <td>453.42</td>\n",
       "      <td>455.09</td>\n",
       "      <td>460</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>453.31</td>\n",
       "      <td>455.1</td>\n",
       "      <td>316</td>\n",
       "      <td>ARCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-12-06 09:37:29</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>454.61</td>\n",
       "      <td>454.64</td>\n",
       "      <td>160</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>80</td>\n",
       "      <td>454.68</td>\n",
       "      <td>...</td>\n",
       "      <td>453.42</td>\n",
       "      <td>455.09</td>\n",
       "      <td>460</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>453.31</td>\n",
       "      <td>455.1</td>\n",
       "      <td>316</td>\n",
       "      <td>ARCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-12-06 09:37:40</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>454.61</td>\n",
       "      <td>454.64</td>\n",
       "      <td>160</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>80</td>\n",
       "      <td>454.68</td>\n",
       "      <td>...</td>\n",
       "      <td>453.42</td>\n",
       "      <td>455.09</td>\n",
       "      <td>460</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>453.31</td>\n",
       "      <td>455.1</td>\n",
       "      <td>316</td>\n",
       "      <td>ARCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-12-06 09:37:51</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>454.61</td>\n",
       "      <td>454.64</td>\n",
       "      <td>160</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>80</td>\n",
       "      <td>454.68</td>\n",
       "      <td>...</td>\n",
       "      <td>453.42</td>\n",
       "      <td>455.09</td>\n",
       "      <td>460</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>453.31</td>\n",
       "      <td>455.1</td>\n",
       "      <td>316</td>\n",
       "      <td>ARCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-12-06 09:38:03</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>454.61</td>\n",
       "      <td>454.64</td>\n",
       "      <td>160</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>80</td>\n",
       "      <td>454.68</td>\n",
       "      <td>...</td>\n",
       "      <td>453.42</td>\n",
       "      <td>455.09</td>\n",
       "      <td>460</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>453.31</td>\n",
       "      <td>455.1</td>\n",
       "      <td>316</td>\n",
       "      <td>ARCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-12-06 09:38:14</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>454.61</td>\n",
       "      <td>454.64</td>\n",
       "      <td>160</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>80</td>\n",
       "      <td>454.68</td>\n",
       "      <td>...</td>\n",
       "      <td>453.42</td>\n",
       "      <td>455.09</td>\n",
       "      <td>460</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>453.31</td>\n",
       "      <td>455.1</td>\n",
       "      <td>316</td>\n",
       "      <td>ARCX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-12-06 09:38:25</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>454.61</td>\n",
       "      <td>454.64</td>\n",
       "      <td>160</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>XNMS</td>\n",
       "      <td>80</td>\n",
       "      <td>454.68</td>\n",
       "      <td>...</td>\n",
       "      <td>453.42</td>\n",
       "      <td>455.09</td>\n",
       "      <td>460</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>ARCX</td>\n",
       "      <td>1</td>\n",
       "      <td>453.31</td>\n",
       "      <td>455.1</td>\n",
       "      <td>316</td>\n",
       "      <td>ARCX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows √ó 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp exch_b_1  size_b_1   bid_1   ask_1  size_a_1 exch_a_1  \\\n",
       "0   2025-12-06 09:35:31     ARCX         1  454.61  454.64       160     XNMS   \n",
       "1   2025-12-06 09:35:42     ARCX         1  454.61  454.64       160     XNMS   \n",
       "2   2025-12-06 09:35:53     ARCX         1  454.61  454.64       160     XNMS   \n",
       "3   2025-12-06 09:36:03     ARCX         1  454.61  454.64       160     XNMS   \n",
       "4   2025-12-06 09:37:18     ARCX         1  454.61  454.64       160     XNMS   \n",
       "5   2025-12-06 09:37:29     ARCX         1  454.61  454.64       160     XNMS   \n",
       "6   2025-12-06 09:37:40     ARCX         1  454.61  454.64       160     XNMS   \n",
       "7   2025-12-06 09:37:51     ARCX         1  454.61  454.64       160     XNMS   \n",
       "8   2025-12-06 09:38:03     ARCX         1  454.61  454.64       160     XNMS   \n",
       "9   2025-12-06 09:38:14     ARCX         1  454.61  454.64       160     XNMS   \n",
       "10  2025-12-06 09:38:25     ARCX         1  454.61  454.64       160     XNMS   \n",
       "\n",
       "   exch_b_2  size_b_2   bid_2  ...  bid_24  ask_24 size_a_24 exch_a_24  \\\n",
       "0      XNMS        80  454.68  ...  453.42  455.09       460      ARCX   \n",
       "1      XNMS        80  454.68  ...  453.42  455.09       460      ARCX   \n",
       "2      XNMS        80  454.68  ...  453.42  455.09       460      ARCX   \n",
       "3      XNMS        80  454.68  ...  453.42  455.09       460      ARCX   \n",
       "4      XNMS        80  454.68  ...  453.42  455.09       460      ARCX   \n",
       "5      XNMS        80  454.68  ...  453.42  455.09       460      ARCX   \n",
       "6      XNMS        80  454.68  ...  453.42  455.09       460      ARCX   \n",
       "7      XNMS        80  454.68  ...  453.42  455.09       460      ARCX   \n",
       "8      XNMS        80  454.68  ...  453.42  455.09       460      ARCX   \n",
       "9      XNMS        80  454.68  ...  453.42  455.09       460      ARCX   \n",
       "10     XNMS        80  454.68  ...  453.42  455.09       460      ARCX   \n",
       "\n",
       "    exch_b_25  size_b_25  bid_25  ask_25 size_a_25 exch_a_25  \n",
       "0        ARCX          1  453.31   455.1       316      ARCX  \n",
       "1        ARCX          1  453.31   455.1       316      ARCX  \n",
       "2        ARCX          1  453.31   455.1       316      ARCX  \n",
       "3        ARCX          1  453.31   455.1       316      ARCX  \n",
       "4        ARCX          1  453.31   455.1       316      ARCX  \n",
       "5        ARCX          1  453.31   455.1       316      ARCX  \n",
       "6        ARCX          1  453.31   455.1       316      ARCX  \n",
       "7        ARCX          1  453.31   455.1       316      ARCX  \n",
       "8        ARCX          1  453.31   455.1       316      ARCX  \n",
       "9        ARCX          1  453.31   455.1       316      ARCX  \n",
       "10       ARCX          1  453.31   455.1       316      ARCX  \n",
       "\n",
       "[11 rows x 151 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
