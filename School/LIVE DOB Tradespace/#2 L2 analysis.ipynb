{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f3b748",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2101194239.py, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 25\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\"Compute total bid/ask notional for a single row (10 levels)\"\"\"\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# CONFIGURATION\n",
    "CLEAN_CSV_FILE = \"fidelity_orderbook_clean.csv\"\n",
    "POLL_INTERVAL = 1.0\n",
    "MAX_POINTS = 10000\n",
    "OFI_LOOKBACK = 8\n",
    "\n",
    "print(f\"Starting depth imbalance + normalized OFI monitor (polling every {POLL_INTERVAL}s)\")\n",
    "print(f\"Source: {CLEAN_CSV_FILE}\")\n",
    "print(f\"OFI lookback: {OFI_LOOKBACK} rows, MAX_POINTS: {MAX_POINTS}\")\n",
    "\n",
    "imbalance_df = pd.DataFrame(columns=[\n",
    "    'timestamp', 'depth_imbalance', 'ask_bid_walk',\n",
    "    'OFI_bid', 'OFI_ask', 'flow_bid', 'flow_ask',\n",
    "    'bid_price', 'ask_price', 'bid_size', 'ask_size',\n",
    "    'total_bid_notional', 'total_ask_notional', 'top3_bid_notional', 'top3_ask_notional'\n",
    "])\n",
    "last_file_size = 0\n",
    "\n",
    "def compute_notional_totals(row):\n",
    "    \"\"\"Compute total bid/ask notional for a single row (10 levels)\"\"\"\n",
    "    total_bid_notional = 0\n",
    "    total_ask_notional = 0\n",
    "    \n",
    "    for lvl in range(1, 11):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        \n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            total_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            total_bid_notional += bid_p * bid_s\n",
    "    \n",
    "    return total_bid_notional, total_ask_notional\n",
    "\n",
    "def compute_top3_notional(row):\n",
    "    \"\"\"Compute top-3 bid/ask notional for normalization\"\"\"\n",
    "    top3_bid_notional = 0\n",
    "    top3_ask_notional = 0\n",
    "    \n",
    "    for lvl in range(1, 4):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        \n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            top3_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            top3_bid_notional += bid_p * bid_s\n",
    "    \n",
    "    return top3_bid_notional, top3_ask_notional\n",
    "\n",
    "print(\"Waiting for clean CSV data...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "\n",
    "        if os.path.exists(CLEAN_CSV_FILE):\n",
    "            current_file_size = os.path.getsize(CLEAN_CSV_FILE)\n",
    "\n",
    "            if current_file_size > last_file_size:\n",
    "                try:\n",
    "                    df_clean = pd.read_csv(CLEAN_CSV_FILE)\n",
    "                    print(f\"Loaded {len(df_clean)} rows from clean CSV\")\n",
    "\n",
    "                    # *** FIXED: Process ALL rows, not just tail(10) ***\n",
    "                    new_rows = df_clean  # ← ALL ROWS!\n",
    "                    new_raw_rows = []\n",
    "\n",
    "                    for _, row in new_rows.iterrows():\n",
    "                        bid_price = pd.to_numeric(row.get('bid_1'), errors='coerce')\n",
    "                        ask_price = pd.to_numeric(row.get('ask_1'), errors='coerce')\n",
    "                        bid_size = pd.to_numeric(row.get('size_b_1'), errors='coerce')\n",
    "                        ask_size = pd.to_numeric(row.get('size_a_1'), errors='coerce')\n",
    "                        \n",
    "                        if pd.isna(bid_price) or pd.isna(ask_price):\n",
    "                            continue\n",
    "                            \n",
    "                        new_raw_rows.append({\n",
    "                            'timestamp': row['timestamp'],\n",
    "                            'bid_price': bid_price, 'ask_price': ask_price,\n",
    "                            'bid_size': bid_size, 'ask_size': ask_size,\n",
    "                            **{col: row[col] for col in row.index if col.startswith(('bid_', 'ask_', 'size_'))}\n",
    "                        })\n",
    "\n",
    "                    # Add new raw data to imbalance_df\n",
    "                    if new_raw_rows:\n",
    "                        new_df = pd.DataFrame(new_raw_rows)\n",
    "                        existing_timestamps = set(imbalance_df['timestamp'])\n",
    "                        fresh_rows = new_df[~new_df['timestamp'].isin(existing_timestamps)]\n",
    "\n",
    "                        print(f\"Found {len(fresh_rows)} NEW rows to add (total will be {len(imbalance_df) + len(fresh_rows)})\")\n",
    "\n",
    "                        if not fresh_rows.empty:\n",
    "                            if imbalance_df.empty:\n",
    "                                imbalance_df = fresh_rows.copy()\n",
    "                            else:\n",
    "                                imbalance_df = pd.concat([imbalance_df, fresh_rows], ignore_index=True)\n",
    "\n",
    "                            # Trim to MAX_POINTS\n",
    "                            if len(imbalance_df) > MAX_POINTS:\n",
    "                                imbalance_df = imbalance_df.tail(MAX_POINTS).reset_index(drop=True)\n",
    "\n",
    "                            # RECOMPUTE ALL METRICS ON FULL MAX_POINTS DATA\n",
    "                            print(f\"\\n--- RECOMPUTING METRICS ON {len(imbalance_df)} rows ---\")\n",
    "                            for i in range(len(imbalance_df)):\n",
    "                                row = imbalance_df.iloc[i]\n",
    "                                \n",
    "                                total_bid_n, total_ask_n = compute_notional_totals(row)\n",
    "                                top3_bid_n, top3_ask_n = compute_top3_notional(row)\n",
    "                                \n",
    "                                imbalance_df.loc[i, 'total_bid_notional'] = total_bid_n\n",
    "                                imbalance_df.loc[i, 'total_ask_notional'] = total_ask_n\n",
    "                                imbalance_df.loc[i, 'top3_bid_notional'] = top3_bid_n\n",
    "                                imbalance_df.loc[i, 'top3_ask_notional'] = top3_ask_n\n",
    "                                \n",
    "                                denom = total_bid_n + total_ask_n\n",
    "                                depth_imbalance = (total_bid_n - total_ask_n) / denom if denom != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'depth_imbalance'] = depth_imbalance\n",
    "                                \n",
    "                                ask_bid_walk = top3_ask_n / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'ask_bid_walk'] = ask_bid_walk\n",
    "                                \n",
    "                                ofi_bid, ofi_ask = 0, 0\n",
    "                                if i >= OFI_LOOKBACK:\n",
    "                                    prior_idx = i - OFI_LOOKBACK\n",
    "                                    prior_bid_n = imbalance_df.loc[prior_idx, 'total_bid_notional']\n",
    "                                    prior_ask_n = imbalance_df.loc[prior_idx, 'total_ask_notional']\n",
    "                                    ofi_bid = total_bid_n - prior_bid_n\n",
    "                                    ofi_ask = total_ask_n - prior_ask_n\n",
    "                                imbalance_df.loc[i, 'OFI_bid'] = ofi_bid\n",
    "                                imbalance_df.loc[i, 'OFI_ask'] = ofi_ask\n",
    "                                \n",
    "                                flow_bid = ofi_bid / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                flow_ask = ofi_ask / top3_ask_n if top3_ask_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'flow_bid'] = flow_bid\n",
    "                                imbalance_df.loc[i, 'flow_ask'] = flow_ask\n",
    "\n",
    "                            latest = imbalance_df.iloc[-1]\n",
    "                            print(f\"[{latest['timestamp']}] Imb:{latest['depth_imbalance']:.3f} W:{latest['ask_bid_walk']:.2f} \"\n",
    "                                  f\"OFI_B:${latest['OFI_bid']:,.0f} OFI_A:${latest['OFI_ask']:,.0f} \"\n",
    "                                  f\"F_B:{latest['flow_bid']:.3f} F_A:{latest['flow_ask']:.3f} \"\n",
    "                                  f\"B1:${latest['bid_price']:.2f}x{int(latest['bid_size'])} \"\n",
    "                                  f\"A1:${latest['ask_price']:.2f}x{int(latest['ask_size'])} \"\n",
    "                                  f\"({len(imbalance_df)} rows)\")\n",
    "\n",
    "                    last_file_size = current_file_size\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Processing error: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Clean CSV not found yet, waiting...\")\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        sleep_time = max(0, POLL_INTERVAL - elapsed)\n",
    "        if sleep_time > 0:\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped by user\")\n",
    "    print(f\"Final DataFrame shape: {imbalance_df.shape}\")\n",
    "    if not imbalance_df.empty:\n",
    "        print(\"\\nLatest 5 rows:\")\n",
    "        print(imbalance_df[['timestamp', 'depth_imbalance', 'ask_bid_walk', 'OFI_bid', 'OFI_ask', \n",
    "                           'flow_bid', 'flow_ask', 'bid_price', 'ask_price']].tail())\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting depth imbalance + normalized OFI monitor (polling every 1.0s)\n",
      "Source: 2fidelity_orderbook_clean.csv\n",
      "OFI lookback: 8 rows, MAX_POINTS: 10000\n",
      "Waiting for clean CSV data...\n",
      "Loaded 610 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 605 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 14:39:40] Imb:0.279 W:1.59 F_B:0.578 F_A:-1.420\n",
      "Loaded 611 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 606 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 14:44:22] Imb:-0.196 W:1.49 F_B:-12.320 F_A:-3.022\n",
      "Loaded 612 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 607 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 14:44:40] Imb:-0.495 W:2.96 F_B:-8.036 F_A:-1.900\n",
      "Loaded 613 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 608 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 14:44:58] Imb:-0.143 W:1.33 F_B:-187.516 F_A:-3.974\n",
      "Loaded 614 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 609 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 14:45:14] Imb:-0.312 W:1.91 F_B:-4.645 F_A:-1.142\n",
      "Loaded 615 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 610 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 14:45:44] Imb:-0.481 W:2.85 F_B:-5.724 F_A:-2.953\n",
      "Loaded 616 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 611 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 14:46:00] Imb:0.092 W:0.83 F_B:-4.185 F_A:-13.743\n",
      "Loaded 617 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 612 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 14:46:15] Imb:0.084 W:0.85 F_B:-1.478 F_A:-2.751\n",
      "Loaded 618 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 613 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 14:46:30] Imb:-0.048 W:1.10 F_B:-7.472 F_A:-3.332\n",
      "Loaded 619 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 614 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 14:46:47] Imb:0.051 W:0.90 F_B:0.222 F_A:-0.283\n",
      "Loaded 620 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 615 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 14:47:02] Imb:-0.443 W:2.59 F_B:0.336 F_A:0.241\n",
      "Loaded 621 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 616 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 14:47:19] Imb:0.531 W:0.31 F_B:0.714 F_A:-0.246\n",
      "Loaded 622 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 617 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 14:47:34] Imb:-0.582 W:3.78 F_B:-0.003 F_A:0.494\n",
      "Loaded 623 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 618 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 14:47:51] Imb:-0.268 W:1.73 F_B:-0.008 F_A:-0.659\n",
      "Loaded 624 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 619 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 14:48:08] Imb:-0.724 W:6.25 F_B:-0.806 F_A:0.760\n",
      "Loaded 625 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 620 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 14:48:25] Imb:-0.193 W:1.48 F_B:-0.618 F_A:0.075\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# CONFIGURATION\n",
    "CLEAN_CSV_FILE = \"2fidelity_orderbook_clean.csv\"\n",
    "POLL_INTERVAL = 1.0\n",
    "MAX_POINTS = 10000\n",
    "OFI_LOOKBACK = 8\n",
    "PICKLE_FILE = \"2imbalance_live.pkl\"  # <---- Added global pickle target\n",
    "\n",
    "print(f\"Starting depth imbalance + normalized OFI monitor (polling every {POLL_INTERVAL}s)\")\n",
    "print(f\"Source: {CLEAN_CSV_FILE}\")\n",
    "print(f\"OFI lookback: {OFI_LOOKBACK} rows, MAX_POINTS: {MAX_POINTS}\")\n",
    "\n",
    "imbalance_df = pd.DataFrame(columns=[\n",
    "    'timestamp', 'depth_imbalance', 'ask_bid_walk',\n",
    "    'OFI_bid', 'OFI_ask', 'flow_bid', 'flow_ask',\n",
    "    'bid_price', 'ask_price', 'bid_size', 'ask_size',\n",
    "    'total_bid_notional', 'total_ask_notional', 'top3_bid_notional', 'top3_ask_notional'\n",
    "])\n",
    "last_file_size = 0\n",
    "\n",
    "\n",
    "def compute_notional_totals(row):\n",
    "    total_bid_notional, total_ask_notional = 0, 0\n",
    "    for lvl in range(1, 11):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            total_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            total_bid_notional += bid_p * bid_s\n",
    "    return total_bid_notional, total_ask_notional\n",
    "\n",
    "\n",
    "def compute_top3_notional(row):\n",
    "    top3_bid_notional, top3_ask_notional = 0, 0\n",
    "    for lvl in range(1, 4):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            top3_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            top3_bid_notional += bid_p * bid_s\n",
    "    return top3_bid_notional, top3_ask_notional\n",
    "\n",
    "\n",
    "print(\"Waiting for clean CSV data...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "\n",
    "        if os.path.exists(CLEAN_CSV_FILE):\n",
    "            current_file_size = os.path.getsize(CLEAN_CSV_FILE)\n",
    "            if current_file_size > last_file_size:\n",
    "                try:\n",
    "                    df_clean = pd.read_csv(CLEAN_CSV_FILE)\n",
    "                    print(f\"Loaded {len(df_clean)} rows from clean CSV\")\n",
    "\n",
    "                    new_rows = df_clean\n",
    "                    new_raw_rows = []\n",
    "                    for _, row in new_rows.iterrows():\n",
    "                        bid_price = pd.to_numeric(row.get('bid_1'), errors='coerce')\n",
    "                        ask_price = pd.to_numeric(row.get('ask_1'), errors='coerce')\n",
    "                        bid_size = pd.to_numeric(row.get('size_b_1'), errors='coerce')\n",
    "                        ask_size = pd.to_numeric(row.get('size_a_1'), errors='coerce')\n",
    "                        if pd.isna(bid_price) or pd.isna(ask_price):\n",
    "                            continue\n",
    "                        new_raw_rows.append({\n",
    "                            'timestamp': row['timestamp'],\n",
    "                            'bid_price': bid_price, 'ask_price': ask_price,\n",
    "                            'bid_size': bid_size, 'ask_size': ask_size,\n",
    "                            **{col: row[col] for col in row.index if col.startswith(('bid_', 'ask_', 'size_'))}\n",
    "                        })\n",
    "\n",
    "                    if new_raw_rows:\n",
    "                        new_df = pd.DataFrame(new_raw_rows)\n",
    "                        existing_timestamps = set(imbalance_df['timestamp'])\n",
    "                        fresh_rows = new_df[~new_df['timestamp'].isin(existing_timestamps)]\n",
    "\n",
    "                        if not fresh_rows.empty:\n",
    "                            if imbalance_df.empty:\n",
    "                                imbalance_df = fresh_rows.copy()\n",
    "                            else:\n",
    "                                imbalance_df = pd.concat([imbalance_df, fresh_rows], ignore_index=True)\n",
    "\n",
    "                            if len(imbalance_df) > MAX_POINTS:\n",
    "                                imbalance_df = imbalance_df.tail(MAX_POINTS).reset_index(drop=True)\n",
    "\n",
    "                            print(f\"\\n--- RECOMPUTING METRICS ON {len(imbalance_df)} rows ---\")\n",
    "                            for i in range(len(imbalance_df)):\n",
    "                                row = imbalance_df.iloc[i]\n",
    "                                total_bid_n, total_ask_n = compute_notional_totals(row)\n",
    "                                top3_bid_n, top3_ask_n = compute_top3_notional(row)\n",
    "\n",
    "                                imbalance_df.loc[i, 'total_bid_notional'] = total_bid_n\n",
    "                                imbalance_df.loc[i, 'total_ask_notional'] = total_ask_n\n",
    "                                imbalance_df.loc[i, 'top3_bid_notional'] = top3_bid_n\n",
    "                                imbalance_df.loc[i, 'top3_ask_notional'] = top3_ask_n\n",
    "\n",
    "                                denom = total_bid_n + total_ask_n\n",
    "                                imb = (total_bid_n - total_ask_n) / denom if denom != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'depth_imbalance'] = imb\n",
    "\n",
    "                                ask_bid_walk = top3_ask_n / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'ask_bid_walk'] = ask_bid_walk\n",
    "\n",
    "                                ofi_bid, ofi_ask = 0, 0\n",
    "                                if i >= OFI_LOOKBACK:\n",
    "                                    p_idx = i - OFI_LOOKBACK\n",
    "                                    prior_bid_n = imbalance_df.loc[p_idx, 'total_bid_notional']\n",
    "                                    prior_ask_n = imbalance_df.loc[p_idx, 'total_ask_notional']\n",
    "                                    ofi_bid = total_bid_n - prior_bid_n\n",
    "                                    ofi_ask = total_ask_n - prior_ask_n\n",
    "                                imbalance_df.loc[i, 'OFI_bid'] = ofi_bid\n",
    "                                imbalance_df.loc[i, 'OFI_ask'] = ofi_ask\n",
    "\n",
    "                                flow_bid = ofi_bid / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                flow_ask = ofi_ask / top3_ask_n if top3_ask_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'flow_bid'] = flow_bid\n",
    "                                imbalance_df.loc[i, 'flow_ask'] = flow_ask\n",
    "\n",
    "                            # Save to pickle for other kernels\n",
    "                            imbalance_df.to_pickle(PICKLE_FILE)\n",
    "                            print(f\"Updated pickle: {PICKLE_FILE}\")\n",
    "\n",
    "                            latest = imbalance_df.iloc[-1]\n",
    "                            print(f\"[{latest['timestamp']}] Imb:{latest['depth_imbalance']:.3f} \"\n",
    "                                  f\"W:{latest['ask_bid_walk']:.2f} F_B:{latest['flow_bid']:.3f} F_A:{latest['flow_ask']:.3f}\")\n",
    "\n",
    "                    last_file_size = current_file_size\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Processing error: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Clean CSV not found yet, waiting...\")\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        time.sleep(max(0, POLL_INTERVAL - elapsed))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped by user\")\n",
    "\n",
    "    if not imbalance_df.empty:\n",
    "        # Save final snapshot\n",
    "        imbalance_df.to_pickle(PICKLE_FILE)\n",
    "        print(f\"Saved final snapshot to {PICKLE_FILE}\")\n",
    "        \n",
    "        # Print final dataframe info\n",
    "        print(f\"\\nFinal DataFrame shape: {imbalance_df.shape}\")\n",
    "        print(\"\\nLatest 10 rows of final data:\")\n",
    "        print(imbalance_df.tail(10).to_string(index=False))\n",
    "\n",
    "        # Optional: print data summary\n",
    "        print(\"\\nColumn summary (non-null counts and dtypes):\")\n",
    "        print(imbalance_df.info())\n",
    "    else:\n",
    "        print(\"No data captured — imbalance_df is empty.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
