{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f3b748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting depth imbalance + normalized OFI monitor (polling every 1.0s)\n",
      "Source: fidelity_orderbook_clean.csv\n",
      "OFI lookback: 8 rows, MAX_POINTS: 10000\n",
      "Waiting for clean CSV data...\n",
      "Loaded 533 rows from clean CSV\n",
      "Found 532 NEW rows to add (total will be 532)\n",
      "\n",
      "--- RECOMPUTING METRICS ON 532 rows ---\n",
      "[2025-12-06 12:18:41] Imb:-0.655 W:50.11 OFI_B:$0 OFI_A:$0 F_B:0.000 F_A:0.000 B1:$454.61x1 A1:$454.64x160 (532 rows)\n",
      "\n",
      "Stopped by user\n",
      "Final DataFrame shape: (532, 59)\n",
      "\n",
      "Latest 5 rows:\n",
      "               timestamp  depth_imbalance  ask_bid_walk  OFI_bid  OFI_ask  \\\n",
      "527  2025-12-06 11:57:03        -0.654939     50.110598      0.0      0.0   \n",
      "528  2025-12-06 12:18:17        -0.654939     50.110598      0.0      0.0   \n",
      "529  2025-12-06 12:18:24        -0.654939     50.110598      0.0      0.0   \n",
      "530  2025-12-06 12:18:32        -0.654939     50.110598      0.0      0.0   \n",
      "531  2025-12-06 12:18:41        -0.654939     50.110598      0.0      0.0   \n",
      "\n",
      "     flow_bid  flow_ask  bid_price  ask_price  \n",
      "527       0.0       0.0     454.61     454.64  \n",
      "528       0.0       0.0     454.61     454.64  \n",
      "529       0.0       0.0     454.61     454.64  \n",
      "530       0.0       0.0     454.61     454.64  \n",
      "531       0.0       0.0     454.61     454.64  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# CONFIGURATION\n",
    "CLEAN_CSV_FILE = \"fidelity_orderbook_clean.csv\"\n",
    "POLL_INTERVAL = 1.0\n",
    "MAX_POINTS = 10000\n",
    "OFI_LOOKBACK = 8\n",
    "\n",
    "print(f\"Starting depth imbalance + normalized OFI monitor (polling every {POLL_INTERVAL}s)\")\n",
    "print(f\"Source: {CLEAN_CSV_FILE}\")\n",
    "print(f\"OFI lookback: {OFI_LOOKBACK} rows, MAX_POINTS: {MAX_POINTS}\")\n",
    "\n",
    "imbalance_df = pd.DataFrame(columns=[\n",
    "    'timestamp', 'depth_imbalance', 'ask_bid_walk',\n",
    "    'OFI_bid', 'OFI_ask', 'flow_bid', 'flow_ask',\n",
    "    'bid_price', 'ask_price', 'bid_size', 'ask_size',\n",
    "    'total_bid_notional', 'total_ask_notional', 'top3_bid_notional', 'top3_ask_notional'\n",
    "])\n",
    "last_file_size = 0\n",
    "\n",
    "def compute_notional_totals(row):\n",
    "    \"\"\"Compute total bid/ask notional for a single row (10 levels)\"\"\"\n",
    "    total_bid_notional = 0\n",
    "    total_ask_notional = 0\n",
    "    \n",
    "    for lvl in range(1, 11):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        \n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            total_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            total_bid_notional += bid_p * bid_s\n",
    "    \n",
    "    return total_bid_notional, total_ask_notional\n",
    "\n",
    "def compute_top3_notional(row):\n",
    "    \"\"\"Compute top-3 bid/ask notional for normalization\"\"\"\n",
    "    top3_bid_notional = 0\n",
    "    top3_ask_notional = 0\n",
    "    \n",
    "    for lvl in range(1, 4):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        \n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            top3_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            top3_bid_notional += bid_p * bid_s\n",
    "    \n",
    "    return top3_bid_notional, top3_ask_notional\n",
    "\n",
    "print(\"Waiting for clean CSV data...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "\n",
    "        if os.path.exists(CLEAN_CSV_FILE):\n",
    "            current_file_size = os.path.getsize(CLEAN_CSV_FILE)\n",
    "\n",
    "            if current_file_size > last_file_size:\n",
    "                try:\n",
    "                    df_clean = pd.read_csv(CLEAN_CSV_FILE)\n",
    "                    print(f\"Loaded {len(df_clean)} rows from clean CSV\")\n",
    "\n",
    "                    # *** FIXED: Process ALL rows, not just tail(10) ***\n",
    "                    new_rows = df_clean  # ← ALL ROWS!\n",
    "                    new_raw_rows = []\n",
    "\n",
    "                    for _, row in new_rows.iterrows():\n",
    "                        bid_price = pd.to_numeric(row.get('bid_1'), errors='coerce')\n",
    "                        ask_price = pd.to_numeric(row.get('ask_1'), errors='coerce')\n",
    "                        bid_size = pd.to_numeric(row.get('size_b_1'), errors='coerce')\n",
    "                        ask_size = pd.to_numeric(row.get('size_a_1'), errors='coerce')\n",
    "                        \n",
    "                        if pd.isna(bid_price) or pd.isna(ask_price):\n",
    "                            continue\n",
    "                            \n",
    "                        new_raw_rows.append({\n",
    "                            'timestamp': row['timestamp'],\n",
    "                            'bid_price': bid_price, 'ask_price': ask_price,\n",
    "                            'bid_size': bid_size, 'ask_size': ask_size,\n",
    "                            **{col: row[col] for col in row.index if col.startswith(('bid_', 'ask_', 'size_'))}\n",
    "                        })\n",
    "\n",
    "                    # Add new raw data to imbalance_df\n",
    "                    if new_raw_rows:\n",
    "                        new_df = pd.DataFrame(new_raw_rows)\n",
    "                        existing_timestamps = set(imbalance_df['timestamp'])\n",
    "                        fresh_rows = new_df[~new_df['timestamp'].isin(existing_timestamps)]\n",
    "\n",
    "                        print(f\"Found {len(fresh_rows)} NEW rows to add (total will be {len(imbalance_df) + len(fresh_rows)})\")\n",
    "\n",
    "                        if not fresh_rows.empty:\n",
    "                            if imbalance_df.empty:\n",
    "                                imbalance_df = fresh_rows.copy()\n",
    "                            else:\n",
    "                                imbalance_df = pd.concat([imbalance_df, fresh_rows], ignore_index=True)\n",
    "\n",
    "                            # Trim to MAX_POINTS\n",
    "                            if len(imbalance_df) > MAX_POINTS:\n",
    "                                imbalance_df = imbalance_df.tail(MAX_POINTS).reset_index(drop=True)\n",
    "\n",
    "                            # RECOMPUTE ALL METRICS ON FULL MAX_POINTS DATA\n",
    "                            print(f\"\\n--- RECOMPUTING METRICS ON {len(imbalance_df)} rows ---\")\n",
    "                            for i in range(len(imbalance_df)):\n",
    "                                row = imbalance_df.iloc[i]\n",
    "                                \n",
    "                                total_bid_n, total_ask_n = compute_notional_totals(row)\n",
    "                                top3_bid_n, top3_ask_n = compute_top3_notional(row)\n",
    "                                \n",
    "                                imbalance_df.loc[i, 'total_bid_notional'] = total_bid_n\n",
    "                                imbalance_df.loc[i, 'total_ask_notional'] = total_ask_n\n",
    "                                imbalance_df.loc[i, 'top3_bid_notional'] = top3_bid_n\n",
    "                                imbalance_df.loc[i, 'top3_ask_notional'] = top3_ask_n\n",
    "                                \n",
    "                                denom = total_bid_n + total_ask_n\n",
    "                                depth_imbalance = (total_bid_n - total_ask_n) / denom if denom != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'depth_imbalance'] = depth_imbalance\n",
    "                                \n",
    "                                ask_bid_walk = top3_ask_n / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'ask_bid_walk'] = ask_bid_walk\n",
    "                                \n",
    "                                ofi_bid, ofi_ask = 0, 0\n",
    "                                if i >= OFI_LOOKBACK:\n",
    "                                    prior_idx = i - OFI_LOOKBACK\n",
    "                                    prior_bid_n = imbalance_df.loc[prior_idx, 'total_bid_notional']\n",
    "                                    prior_ask_n = imbalance_df.loc[prior_idx, 'total_ask_notional']\n",
    "                                    ofi_bid = total_bid_n - prior_bid_n\n",
    "                                    ofi_ask = total_ask_n - prior_ask_n\n",
    "                                imbalance_df.loc[i, 'OFI_bid'] = ofi_bid\n",
    "                                imbalance_df.loc[i, 'OFI_ask'] = ofi_ask\n",
    "                                \n",
    "                                flow_bid = ofi_bid / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                flow_ask = ofi_ask / top3_ask_n if top3_ask_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'flow_bid'] = flow_bid\n",
    "                                imbalance_df.loc[i, 'flow_ask'] = flow_ask\n",
    "\n",
    "                            latest = imbalance_df.iloc[-1]\n",
    "                            print(f\"[{latest['timestamp']}] Imb:{latest['depth_imbalance']:.3f} W:{latest['ask_bid_walk']:.2f} \"\n",
    "                                  f\"OFI_B:${latest['OFI_bid']:,.0f} OFI_A:${latest['OFI_ask']:,.0f} \"\n",
    "                                  f\"F_B:{latest['flow_bid']:.3f} F_A:{latest['flow_ask']:.3f} \"\n",
    "                                  f\"B1:${latest['bid_price']:.2f}x{int(latest['bid_size'])} \"\n",
    "                                  f\"A1:${latest['ask_price']:.2f}x{int(latest['ask_size'])} \"\n",
    "                                  f\"({len(imbalance_df)} rows)\")\n",
    "\n",
    "                    last_file_size = current_file_size\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Processing error: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Clean CSV not found yet, waiting...\")\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        sleep_time = max(0, POLL_INTERVAL - elapsed)\n",
    "        if sleep_time > 0:\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped by user\")\n",
    "    print(f\"Final DataFrame shape: {imbalance_df.shape}\")\n",
    "    if not imbalance_df.empty:\n",
    "        print(\"\\nLatest 5 rows:\")\n",
    "        print(imbalance_df[['timestamp', 'depth_imbalance', 'ask_bid_walk', 'OFI_bid', 'OFI_ask', \n",
    "                           'flow_bid', 'flow_ask', 'bid_price', 'ask_price']].tail())\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8627968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting depth imbalance + normalized OFI monitor (polling every 1.0s)\n",
      "Source: fidelity_orderbook_clean.csv\n",
      "OFI lookback: 8 rows, MAX_POINTS: 10000\n",
      "Waiting for clean CSV data...\n",
      "Loaded 533 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 532 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:18:41] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 534 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 533 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:32:46] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 535 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 534 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:32:54] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 536 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 535 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:33:02] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 537 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 536 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:33:10] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 538 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 537 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:33:18] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 539 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 538 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:33:26] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 540 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 539 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:33:34] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 541 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 540 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:33:42] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 542 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 541 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:33:49] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 543 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 542 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:33:57] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 544 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 543 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:34:05] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 545 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 544 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:34:13] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 546 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 545 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:34:21] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 547 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 546 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:34:29] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 548 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 547 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:34:37] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 549 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 548 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:34:45] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 550 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 549 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:34:52] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 551 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 550 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:35:00] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 552 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 551 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:35:08] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 553 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 552 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:35:17] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 554 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 553 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:35:25] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 555 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 554 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:35:33] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 556 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 555 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:35:40] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 557 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 556 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:35:48] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 558 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 557 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:35:56] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 559 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 558 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:36:04] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 560 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 559 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:36:11] Imb:-0.655 W:50.11 F_B:0.000 F_A:-0.000\n",
      "Loaded 561 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 560 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:36:18] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 562 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 561 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:36:26] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 563 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 562 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:36:33] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 564 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 563 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:36:42] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "Loaded 565 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 564 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-06 12:36:50] Imb:-0.655 W:50.11 F_B:0.000 F_A:0.000\n",
      "\n",
      "Stopped by user\n",
      "Saved final snapshot to imbalance_live.pkl\n",
      "\n",
      "Final DataFrame shape: (564, 59)\n",
      "\n",
      "Latest 10 rows of final data:\n",
      "          timestamp  bid_price  ask_price  bid_size  ask_size size_b_1  bid_1  ask_1 size_a_1 size_b_2  bid_2  ask_2 size_a_2 size_b_3  bid_3  ask_3  size_a_3  size_b_4  bid_4  ask_4  size_a_4  size_b_5  bid_5  ask_5 size_a_5 size_b_6         bid_6         ask_6 size_a_6  size_b_7  bid_7  ask_7  size_a_7  size_b_8  bid_8  ask_8  size_a_8  size_b_9  bid_9  ask_9  size_a_9  size_b_10  bid_10  ask_10  size_a_10  size_b_11  bid_11  ask_11  size_a_11  total_bid_notional  total_ask_notional  top3_bid_notional  top3_ask_notional  depth_imbalance  ask_bid_walk  OFI_bid  OFI_ask  flow_bid  flow_ask\n",
      "2025-12-06 12:35:40     454.61     454.64         1       160        1 454.61 454.64      160       80 454.68 464.66     3884        3 454.55 454.69      80.0     700.0  454.5  454.7     135.0      80.0 454.45 454.75        I  560 198 454.45 454.40 454.78 454.79      I 1      21.0 454.35  454.8       2.0       1.0  454.3 454.81      40.0      21.0 454.25 454.83       6.0       10.0  454.24  454.84        4.0        NaN     NaN     NaN        NaN           416775.96          1998891.88           38192.66         1913857.04        -0.654939     50.110598      0.0     0.00       0.0  0.000000\n",
      "2025-12-06 12:35:48     454.61     454.64         1       160        1 454.61 454.64      160       80 454.68 464.66     3884        3 454.55 454.69      80.0     700.0  454.5  454.7     135.0      80.0 454.45 454.75        I  560 198 454.45 454.40 454.78 454.79      I 1      21.0 454.35  454.8       2.0       1.0  454.3 454.81      40.0      21.0 454.25 454.83       6.0       10.0  454.24  454.84        4.0        NaN     NaN     NaN        NaN           416775.96          1998891.88           38192.66         1913857.04        -0.654939     50.110598      0.0     0.00       0.0  0.000000\n",
      "2025-12-06 12:35:56     454.61     454.64         1       160        1 454.61 454.64      160       80 454.68 464.66     3884        3 454.55 454.69      80.0     700.0  454.5  454.7     135.0      80.0 454.45 454.75        I  560 198 454.45 454.40 454.78 454.79      I 1      21.0 454.35  454.8       2.0       1.0  454.3 454.81      40.0      21.0 454.25 454.83       6.0       10.0  454.24  454.84        4.0        NaN     NaN     NaN        NaN           416775.96          1998891.88           38192.66         1913857.04        -0.654939     50.110598      0.0     0.00       0.0  0.000000\n",
      "2025-12-06 12:36:04     454.61     454.64         1       160        1 454.61 454.64      160       80 454.68 464.66     3884        3 454.55 454.69      80.0     700.0  454.5  454.7     135.0      80.0 454.45 454.75        I  560 198 454.45 454.40 454.78 454.79      I 1      21.0 454.35  454.8       2.0       1.0  454.3 454.81      40.0      21.0 454.25 454.83       6.0       10.0  454.24  454.84        4.0        NaN     NaN     NaN        NaN           416775.96          1998891.88           38192.66         1913857.04        -0.654939     50.110598      0.0     0.00       0.0  0.000000\n",
      "2025-12-06 12:36:11     454.61     454.64         1       160        1 454.61 454.64      160       80 454.68 464.66     3884        3 454.55 454.69      80.0     700.0  454.5  454.7     135.0      80.0 454.45 454.75        I  560 198 454.45 454.40 454.78 454.79      I 1      21.0 454.35  454.8       2.0       1.0  454.3 454.81      40.0      21.0 454.25 454.83       6.0       10.0  454.24  454.84        4.0        NaN     NaN     NaN        NaN           416775.96          1998891.88           38192.66         1913857.04        -0.654939     50.110598      0.0   -77.68       0.0 -0.000041\n",
      "2025-12-06 12:36:18     454.61     454.64         1       160        1 454.61 454.64      160       80 454.68 464.66     3884        3 454.55 454.69      80.0     700.0  454.5  454.7     135.0      80.0 454.45 454.75        I  560 198 454.45 454.40 454.78 454.79      I 1      21.0 454.35  454.8       2.0       1.0  454.3 454.81      40.0      21.0 454.25 454.83       6.0       10.0  454.24  454.84        4.0        NaN     NaN     NaN        NaN           416775.96          1998891.88           38192.66         1913857.04        -0.654939     50.110598      0.0     0.00       0.0  0.000000\n",
      "2025-12-06 12:36:26     454.61     454.64         1       160        1 454.61 454.64      160       80 454.68 464.66     3884        3 454.55 454.69      80.0     700.0  454.5  454.7     135.0      80.0 454.45 454.75        I  560 198 454.45 454.40 454.78 454.79      I 1      21.0 454.35  454.8       2.0       1.0  454.3 454.81      40.0      21.0 454.25 454.83       6.0       10.0  454.24  454.84        4.0        NaN     NaN     NaN        NaN           416775.96          1998891.88           38192.66         1913857.04        -0.654939     50.110598      0.0     0.00       0.0  0.000000\n",
      "2025-12-06 12:36:33     454.61     454.64         1       160        1 454.61 454.64      160       80 454.68 464.66     3884        3 454.55 454.69      80.0     700.0  454.5  454.7     135.0      80.0 454.45 454.75        I  560 198 454.45 454.40 454.78 454.79      I 1      21.0 454.35  454.8       2.0       1.0  454.3 454.81      40.0      21.0 454.25 454.83       6.0       10.0  454.24  454.84        4.0        NaN     NaN     NaN        NaN           416775.96          1998891.88           38192.66         1913857.04        -0.654939     50.110598      0.0     0.00       0.0  0.000000\n",
      "2025-12-06 12:36:42     454.61     454.64         1       160        1 454.61 454.64      160       80 454.68 464.66     3884        3 454.55 454.69      80.0     700.0  454.5  454.7     135.0      80.0 454.45 454.75        I  560 198 454.45 454.40 454.78 454.79      I 1      21.0 454.35  454.8       2.0       1.0  454.3 454.81      40.0      21.0 454.25 454.83       6.0       10.0  454.24  454.84        4.0        NaN     NaN     NaN        NaN           416775.96          1998891.88           38192.66         1913857.04        -0.654939     50.110598      0.0     0.00       0.0  0.000000\n",
      "2025-12-06 12:36:50     454.61     454.64         1       160        1 454.61 454.64      160       80 454.68 464.66     3884        3 454.55 454.69      80.0     700.0  454.5  454.7     135.0      80.0 454.45 454.75        I  560 198 454.45 454.40 454.78 454.79      I 1      21.0 454.35  454.8       2.0       1.0  454.3 454.81      40.0      21.0 454.25 454.83       6.0       10.0  454.24  454.84        4.0        NaN     NaN     NaN        NaN           416775.96          1998891.88           38192.66         1913857.04        -0.654939     50.110598      0.0     0.00       0.0  0.000000\n",
      "\n",
      "Column summary (non-null counts and dtypes):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 564 entries, 0 to 563\n",
      "Data columns (total 59 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   timestamp           564 non-null    object \n",
      " 1   bid_price           564 non-null    float64\n",
      " 2   ask_price           564 non-null    float64\n",
      " 3   bid_size            564 non-null    int64  \n",
      " 4   ask_size            564 non-null    int64  \n",
      " 5   size_b_1            564 non-null    object \n",
      " 6   bid_1               564 non-null    object \n",
      " 7   ask_1               564 non-null    object \n",
      " 8   size_a_1            564 non-null    object \n",
      " 9   size_b_2            564 non-null    object \n",
      " 10  bid_2               564 non-null    object \n",
      " 11  ask_2               564 non-null    object \n",
      " 12  size_a_2            564 non-null    object \n",
      " 13  size_b_3            564 non-null    object \n",
      " 14  bid_3               564 non-null    object \n",
      " 15  ask_3               564 non-null    object \n",
      " 16  size_a_3            564 non-null    float64\n",
      " 17  size_b_4            564 non-null    float64\n",
      " 18  bid_4               564 non-null    float64\n",
      " 19  ask_4               564 non-null    float64\n",
      " 20  size_a_4            564 non-null    float64\n",
      " 21  size_b_5            564 non-null    float64\n",
      " 22  bid_5               564 non-null    float64\n",
      " 23  ask_5               564 non-null    float64\n",
      " 24  size_a_5            564 non-null    object \n",
      " 25  size_b_6            564 non-null    object \n",
      " 26  bid_6               564 non-null    object \n",
      " 27  ask_6               564 non-null    object \n",
      " 28  size_a_6            564 non-null    object \n",
      " 29  size_b_7            564 non-null    float64\n",
      " 30  bid_7               564 non-null    float64\n",
      " 31  ask_7               564 non-null    float64\n",
      " 32  size_a_7            564 non-null    float64\n",
      " 33  size_b_8            564 non-null    float64\n",
      " 34  bid_8               564 non-null    float64\n",
      " 35  ask_8               564 non-null    float64\n",
      " 36  size_a_8            564 non-null    float64\n",
      " 37  size_b_9            564 non-null    float64\n",
      " 38  bid_9               564 non-null    float64\n",
      " 39  ask_9               564 non-null    float64\n",
      " 40  size_a_9            564 non-null    float64\n",
      " 41  size_b_10           564 non-null    float64\n",
      " 42  bid_10              564 non-null    float64\n",
      " 43  ask_10              564 non-null    float64\n",
      " 44  size_a_10           564 non-null    float64\n",
      " 45  size_b_11           1 non-null      float64\n",
      " 46  bid_11              1 non-null      float64\n",
      " 47  ask_11              1 non-null      float64\n",
      " 48  size_a_11           1 non-null      float64\n",
      " 49  total_bid_notional  564 non-null    float64\n",
      " 50  total_ask_notional  564 non-null    float64\n",
      " 51  top3_bid_notional   564 non-null    float64\n",
      " 52  top3_ask_notional   564 non-null    float64\n",
      " 53  depth_imbalance     564 non-null    float64\n",
      " 54  ask_bid_walk        564 non-null    float64\n",
      " 55  OFI_bid             564 non-null    float64\n",
      " 56  OFI_ask             564 non-null    float64\n",
      " 57  flow_bid            564 non-null    float64\n",
      " 58  flow_ask            564 non-null    float64\n",
      "dtypes: float64(40), int64(2), object(17)\n",
      "memory usage: 260.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# CONFIGURATION\n",
    "CLEAN_CSV_FILE = \"fidelity_orderbook_clean.csv\"\n",
    "POLL_INTERVAL = 1.0\n",
    "MAX_POINTS = 10000\n",
    "OFI_LOOKBACK = 8\n",
    "PICKLE_FILE = \"imbalance_live.pkl\"  # <---- Added global pickle target\n",
    "\n",
    "print(f\"Starting depth imbalance + normalized OFI monitor (polling every {POLL_INTERVAL}s)\")\n",
    "print(f\"Source: {CLEAN_CSV_FILE}\")\n",
    "print(f\"OFI lookback: {OFI_LOOKBACK} rows, MAX_POINTS: {MAX_POINTS}\")\n",
    "\n",
    "imbalance_df = pd.DataFrame(columns=[\n",
    "    'timestamp', 'depth_imbalance', 'ask_bid_walk',\n",
    "    'OFI_bid', 'OFI_ask', 'flow_bid', 'flow_ask',\n",
    "    'bid_price', 'ask_price', 'bid_size', 'ask_size',\n",
    "    'total_bid_notional', 'total_ask_notional', 'top3_bid_notional', 'top3_ask_notional'\n",
    "])\n",
    "last_file_size = 0\n",
    "\n",
    "\n",
    "def compute_notional_totals(row):\n",
    "    total_bid_notional, total_ask_notional = 0, 0\n",
    "    for lvl in range(1, 11):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            total_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            total_bid_notional += bid_p * bid_s\n",
    "    return total_bid_notional, total_ask_notional\n",
    "\n",
    "\n",
    "def compute_top3_notional(row):\n",
    "    top3_bid_notional, top3_ask_notional = 0, 0\n",
    "    for lvl in range(1, 4):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            top3_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            top3_bid_notional += bid_p * bid_s\n",
    "    return top3_bid_notional, top3_ask_notional\n",
    "\n",
    "\n",
    "print(\"Waiting for clean CSV data...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "\n",
    "        if os.path.exists(CLEAN_CSV_FILE):\n",
    "            current_file_size = os.path.getsize(CLEAN_CSV_FILE)\n",
    "            if current_file_size > last_file_size:\n",
    "                try:\n",
    "                    df_clean = pd.read_csv(CLEAN_CSV_FILE)\n",
    "                    print(f\"Loaded {len(df_clean)} rows from clean CSV\")\n",
    "\n",
    "                    new_rows = df_clean\n",
    "                    new_raw_rows = []\n",
    "                    for _, row in new_rows.iterrows():\n",
    "                        bid_price = pd.to_numeric(row.get('bid_1'), errors='coerce')\n",
    "                        ask_price = pd.to_numeric(row.get('ask_1'), errors='coerce')\n",
    "                        bid_size = pd.to_numeric(row.get('size_b_1'), errors='coerce')\n",
    "                        ask_size = pd.to_numeric(row.get('size_a_1'), errors='coerce')\n",
    "                        if pd.isna(bid_price) or pd.isna(ask_price):\n",
    "                            continue\n",
    "                        new_raw_rows.append({\n",
    "                            'timestamp': row['timestamp'],\n",
    "                            'bid_price': bid_price, 'ask_price': ask_price,\n",
    "                            'bid_size': bid_size, 'ask_size': ask_size,\n",
    "                            **{col: row[col] for col in row.index if col.startswith(('bid_', 'ask_', 'size_'))}\n",
    "                        })\n",
    "\n",
    "                    if new_raw_rows:\n",
    "                        new_df = pd.DataFrame(new_raw_rows)\n",
    "                        existing_timestamps = set(imbalance_df['timestamp'])\n",
    "                        fresh_rows = new_df[~new_df['timestamp'].isin(existing_timestamps)]\n",
    "\n",
    "                        if not fresh_rows.empty:\n",
    "                            if imbalance_df.empty:\n",
    "                                imbalance_df = fresh_rows.copy()\n",
    "                            else:\n",
    "                                imbalance_df = pd.concat([imbalance_df, fresh_rows], ignore_index=True)\n",
    "\n",
    "                            if len(imbalance_df) > MAX_POINTS:\n",
    "                                imbalance_df = imbalance_df.tail(MAX_POINTS).reset_index(drop=True)\n",
    "\n",
    "                            print(f\"\\n--- RECOMPUTING METRICS ON {len(imbalance_df)} rows ---\")\n",
    "                            for i in range(len(imbalance_df)):\n",
    "                                row = imbalance_df.iloc[i]\n",
    "                                total_bid_n, total_ask_n = compute_notional_totals(row)\n",
    "                                top3_bid_n, top3_ask_n = compute_top3_notional(row)\n",
    "\n",
    "                                imbalance_df.loc[i, 'total_bid_notional'] = total_bid_n\n",
    "                                imbalance_df.loc[i, 'total_ask_notional'] = total_ask_n\n",
    "                                imbalance_df.loc[i, 'top3_bid_notional'] = top3_bid_n\n",
    "                                imbalance_df.loc[i, 'top3_ask_notional'] = top3_ask_n\n",
    "\n",
    "                                denom = total_bid_n + total_ask_n\n",
    "                                imb = (total_bid_n - total_ask_n) / denom if denom != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'depth_imbalance'] = imb\n",
    "\n",
    "                                ask_bid_walk = top3_ask_n / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'ask_bid_walk'] = ask_bid_walk\n",
    "\n",
    "                                ofi_bid, ofi_ask = 0, 0\n",
    "                                if i >= OFI_LOOKBACK:\n",
    "                                    p_idx = i - OFI_LOOKBACK\n",
    "                                    prior_bid_n = imbalance_df.loc[p_idx, 'total_bid_notional']\n",
    "                                    prior_ask_n = imbalance_df.loc[p_idx, 'total_ask_notional']\n",
    "                                    ofi_bid = total_bid_n - prior_bid_n\n",
    "                                    ofi_ask = total_ask_n - prior_ask_n\n",
    "                                imbalance_df.loc[i, 'OFI_bid'] = ofi_bid\n",
    "                                imbalance_df.loc[i, 'OFI_ask'] = ofi_ask\n",
    "\n",
    "                                flow_bid = ofi_bid / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                flow_ask = ofi_ask / top3_ask_n if top3_ask_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'flow_bid'] = flow_bid\n",
    "                                imbalance_df.loc[i, 'flow_ask'] = flow_ask\n",
    "\n",
    "                            # Save to pickle for other kernels\n",
    "                            imbalance_df.to_pickle(PICKLE_FILE)\n",
    "                            print(f\"Updated pickle: {PICKLE_FILE}\")\n",
    "\n",
    "                            latest = imbalance_df.iloc[-1]\n",
    "                            print(f\"[{latest['timestamp']}] Imb:{latest['depth_imbalance']:.3f} \"\n",
    "                                  f\"W:{latest['ask_bid_walk']:.2f} F_B:{latest['flow_bid']:.3f} F_A:{latest['flow_ask']:.3f}\")\n",
    "\n",
    "                    last_file_size = current_file_size\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Processing error: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Clean CSV not found yet, waiting...\")\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        time.sleep(max(0, POLL_INTERVAL - elapsed))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped by user\")\n",
    "\n",
    "    if not imbalance_df.empty:\n",
    "        # Save final snapshot\n",
    "        imbalance_df.to_pickle(PICKLE_FILE)\n",
    "        print(f\"Saved final snapshot to {PICKLE_FILE}\")\n",
    "        \n",
    "        # Print final dataframe info\n",
    "        print(f\"\\nFinal DataFrame shape: {imbalance_df.shape}\")\n",
    "        print(\"\\nLatest 10 rows of final data:\")\n",
    "        print(imbalance_df.tail(10).to_string(index=False))\n",
    "\n",
    "        # Optional: print data summary\n",
    "        print(\"\\nColumn summary (non-null counts and dtypes):\")\n",
    "        print(imbalance_df.info())\n",
    "    else:\n",
    "        print(\"No data captured — imbalance_df is empty.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
