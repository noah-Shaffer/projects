{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f3b748",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2101194239.py, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 25\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\"Compute total bid/ask notional for a single row (10 levels)\"\"\"\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# CONFIGURATION\n",
    "CLEAN_CSV_FILE = \"fidelity_orderbook_clean.csv\"\n",
    "POLL_INTERVAL = 1.0\n",
    "MAX_POINTS = 10000\n",
    "OFI_LOOKBACK = 8\n",
    "\n",
    "print(f\"Starting depth imbalance + normalized OFI monitor (polling every {POLL_INTERVAL}s)\")\n",
    "print(f\"Source: {CLEAN_CSV_FILE}\")\n",
    "print(f\"OFI lookback: {OFI_LOOKBACK} rows, MAX_POINTS: {MAX_POINTS}\")\n",
    "\n",
    "imbalance_df = pd.DataFrame(columns=[\n",
    "    'timestamp', 'depth_imbalance', 'ask_bid_walk',\n",
    "    'OFI_bid', 'OFI_ask', 'flow_bid', 'flow_ask',\n",
    "    'bid_price', 'ask_price', 'bid_size', 'ask_size',\n",
    "    'total_bid_notional', 'total_ask_notional', 'top3_bid_notional', 'top3_ask_notional'\n",
    "])\n",
    "last_file_size = 0\n",
    "\n",
    "def compute_notional_totals(row):\n",
    "    \"\"\"Compute total bid/ask notional for a single row (10 levels)\"\"\"\n",
    "    total_bid_notional = 0\n",
    "    total_ask_notional = 0\n",
    "    \n",
    "    for lvl in range(1, 11):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        \n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            total_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            total_bid_notional += bid_p * bid_s\n",
    "    \n",
    "    return total_bid_notional, total_ask_notional\n",
    "\n",
    "def compute_top3_notional(row):\n",
    "    \"\"\"Compute top-3 bid/ask notional for normalization\"\"\"\n",
    "    top3_bid_notional = 0\n",
    "    top3_ask_notional = 0\n",
    "    \n",
    "    for lvl in range(1, 4):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        \n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            top3_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            top3_bid_notional += bid_p * bid_s\n",
    "    \n",
    "    return top3_bid_notional, top3_ask_notional\n",
    "\n",
    "print(\"Waiting for clean CSV data...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "\n",
    "        if os.path.exists(CLEAN_CSV_FILE):\n",
    "            current_file_size = os.path.getsize(CLEAN_CSV_FILE)\n",
    "\n",
    "            if current_file_size > last_file_size:\n",
    "                try:\n",
    "                    df_clean = pd.read_csv(CLEAN_CSV_FILE)\n",
    "                    print(f\"Loaded {len(df_clean)} rows from clean CSV\")\n",
    "\n",
    "                    # *** FIXED: Process ALL rows, not just tail(10) ***\n",
    "                    new_rows = df_clean  # ← ALL ROWS!\n",
    "                    new_raw_rows = []\n",
    "\n",
    "                    for _, row in new_rows.iterrows():\n",
    "                        bid_price = pd.to_numeric(row.get('bid_1'), errors='coerce')\n",
    "                        ask_price = pd.to_numeric(row.get('ask_1'), errors='coerce')\n",
    "                        bid_size = pd.to_numeric(row.get('size_b_1'), errors='coerce')\n",
    "                        ask_size = pd.to_numeric(row.get('size_a_1'), errors='coerce')\n",
    "                        \n",
    "                        if pd.isna(bid_price) or pd.isna(ask_price):\n",
    "                            continue\n",
    "                            \n",
    "                        new_raw_rows.append({\n",
    "                            'timestamp': row['timestamp'],\n",
    "                            'bid_price': bid_price, 'ask_price': ask_price,\n",
    "                            'bid_size': bid_size, 'ask_size': ask_size,\n",
    "                            **{col: row[col] for col in row.index if col.startswith(('bid_', 'ask_', 'size_'))}\n",
    "                        })\n",
    "\n",
    "                    # Add new raw data to imbalance_df\n",
    "                    if new_raw_rows:\n",
    "                        new_df = pd.DataFrame(new_raw_rows)\n",
    "                        existing_timestamps = set(imbalance_df['timestamp'])\n",
    "                        fresh_rows = new_df[~new_df['timestamp'].isin(existing_timestamps)]\n",
    "\n",
    "                        print(f\"Found {len(fresh_rows)} NEW rows to add (total will be {len(imbalance_df) + len(fresh_rows)})\")\n",
    "\n",
    "                        if not fresh_rows.empty:\n",
    "                            if imbalance_df.empty:\n",
    "                                imbalance_df = fresh_rows.copy()\n",
    "                            else:\n",
    "                                imbalance_df = pd.concat([imbalance_df, fresh_rows], ignore_index=True)\n",
    "\n",
    "                            # Trim to MAX_POINTS\n",
    "                            if len(imbalance_df) > MAX_POINTS:\n",
    "                                imbalance_df = imbalance_df.tail(MAX_POINTS).reset_index(drop=True)\n",
    "\n",
    "                            # RECOMPUTE ALL METRICS ON FULL MAX_POINTS DATA\n",
    "                            print(f\"\\n--- RECOMPUTING METRICS ON {len(imbalance_df)} rows ---\")\n",
    "                            for i in range(len(imbalance_df)):\n",
    "                                row = imbalance_df.iloc[i]\n",
    "                                \n",
    "                                total_bid_n, total_ask_n = compute_notional_totals(row)\n",
    "                                top3_bid_n, top3_ask_n = compute_top3_notional(row)\n",
    "                                \n",
    "                                imbalance_df.loc[i, 'total_bid_notional'] = total_bid_n\n",
    "                                imbalance_df.loc[i, 'total_ask_notional'] = total_ask_n\n",
    "                                imbalance_df.loc[i, 'top3_bid_notional'] = top3_bid_n\n",
    "                                imbalance_df.loc[i, 'top3_ask_notional'] = top3_ask_n\n",
    "                                \n",
    "                                denom = total_bid_n + total_ask_n\n",
    "                                depth_imbalance = (total_bid_n - total_ask_n) / denom if denom != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'depth_imbalance'] = depth_imbalance\n",
    "                                \n",
    "                                ask_bid_walk = top3_ask_n / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'ask_bid_walk'] = ask_bid_walk\n",
    "                                \n",
    "                                ofi_bid, ofi_ask = 0, 0\n",
    "                                if i >= OFI_LOOKBACK:\n",
    "                                    prior_idx = i - OFI_LOOKBACK\n",
    "                                    prior_bid_n = imbalance_df.loc[prior_idx, 'total_bid_notional']\n",
    "                                    prior_ask_n = imbalance_df.loc[prior_idx, 'total_ask_notional']\n",
    "                                    ofi_bid = total_bid_n - prior_bid_n\n",
    "                                    ofi_ask = total_ask_n - prior_ask_n\n",
    "                                imbalance_df.loc[i, 'OFI_bid'] = ofi_bid\n",
    "                                imbalance_df.loc[i, 'OFI_ask'] = ofi_ask\n",
    "                                \n",
    "                                flow_bid = ofi_bid / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                flow_ask = ofi_ask / top3_ask_n if top3_ask_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'flow_bid'] = flow_bid\n",
    "                                imbalance_df.loc[i, 'flow_ask'] = flow_ask\n",
    "\n",
    "                            latest = imbalance_df.iloc[-1]\n",
    "                            print(f\"[{latest['timestamp']}] Imb:{latest['depth_imbalance']:.3f} W:{latest['ask_bid_walk']:.2f} \"\n",
    "                                  f\"OFI_B:${latest['OFI_bid']:,.0f} OFI_A:${latest['OFI_ask']:,.0f} \"\n",
    "                                  f\"F_B:{latest['flow_bid']:.3f} F_A:{latest['flow_ask']:.3f} \"\n",
    "                                  f\"B1:${latest['bid_price']:.2f}x{int(latest['bid_size'])} \"\n",
    "                                  f\"A1:${latest['ask_price']:.2f}x{int(latest['ask_size'])} \"\n",
    "                                  f\"({len(imbalance_df)} rows)\")\n",
    "\n",
    "                    last_file_size = current_file_size\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Processing error: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Clean CSV not found yet, waiting...\")\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        sleep_time = max(0, POLL_INTERVAL - elapsed)\n",
    "        if sleep_time > 0:\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped by user\")\n",
    "    print(f\"Final DataFrame shape: {imbalance_df.shape}\")\n",
    "    if not imbalance_df.empty:\n",
    "        print(\"\\nLatest 5 rows:\")\n",
    "        print(imbalance_df[['timestamp', 'depth_imbalance', 'ask_bid_walk', 'OFI_bid', 'OFI_ask', \n",
    "                           'flow_bid', 'flow_ask', 'bid_price', 'ask_price']].tail())\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8627968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting depth imbalance + normalized OFI monitor (polling every 1.0s)\n",
      "Source: 2fidelity_orderbook_clean.csv\n",
      "OFI lookback: 8 rows, MAX_POINTS: 10000\n",
      "Waiting for clean CSV data...\n",
      "Loaded 808 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 793 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 15:41:22] Imb:0.408 W:0.42 F_B:0.538 F_A:-0.721\n",
      "Loaded 809 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 794 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 15:41:38] Imb:1.000 W:0.00 F_B:-2.625 F_A:nan\n",
      "Loaded 810 rows from clean CSV\n",
      "Loaded 811 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 795 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 15:42:09] Imb:1.000 W:0.00 F_B:-3.495 F_A:nan\n",
      "Loaded 812 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 796 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 15:42:26] Imb:-0.097 W:1.21 F_B:-1.577 F_A:-0.110\n",
      "Loaded 813 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 797 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 15:42:42] Imb:0.178 W:0.70 F_B:0.516 F_A:0.466\n",
      "Loaded 814 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 798 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 15:42:57] Imb:-0.270 W:1.74 F_B:0.456 F_A:1.000\n",
      "Loaded 815 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 799 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 15:43:13] Imb:-0.767 W:7.57 F_B:-1.225 F_A:0.702\n",
      "Loaded 816 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 800 rows ---\n",
      "Updated pickle: 2imbalance_live.pkl\n",
      "[2025-12-08 15:43:29] Imb:0.133 W:0.77 F_B:0.026 F_A:0.185\n",
      "\n",
      "Stopped by user\n",
      "Saved final snapshot to 2imbalance_live.pkl\n",
      "\n",
      "Final DataFrame shape: (800, 47)\n",
      "\n",
      "Latest 10 rows of final data:\n",
      "          timestamp  bid_price  ask_price  bid_size  ask_size size_b_1 bid_1 ask_1  size_a_1 size_b_2 bid_2     ask_2 size_a_2 size_b_3 bid_3 ask_3 size_a_3 size_b_4  bid_4  ask_4 size_a_4 size_b_5 bid_5  ask_5 size_a_5 size_b_6 bid_6  ask_6 size_a_6 size_b_7 bid_7 ask_7 size_a_7 size_b_8 bid_8  ask_8 size_a_8  total_bid_notional  total_ask_notional  top3_bid_notional  top3_ask_notional  depth_imbalance  ask_bid_walk  OFI_bid  OFI_ask  flow_bid  flow_ask\n",
      "2025-12-08 15:40:50       1.75       1.77     10.00      10.0       10  1.75  1.77        10       10  1.75      1.78        6        2  1.75  1.78        6      NaN    NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN   NaN      NaN      NaN   NaN    NaN      NaN             38.5000               39.06            38.5000              39.06        -0.007220      1.014545  22.9300     3.66  0.595584  0.093702\n",
      "2025-12-08 15:41:05       1.74       1.78     16.00      17.0       16  1.74  1.78        17       10  1.74      1.78        4       14  1.73  1.78        4      NaN    NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN   NaN      NaN      NaN   NaN    NaN      NaN             69.4600               44.50            69.4600              44.50         0.219024      0.640656  43.5100    25.07  0.626404  0.563371\n",
      "2025-12-08 15:41:22       1.74       1.76     18.00       5.0       18  1.74  1.76         5       13  1.74      1.76        5       10  1.74  1.77        7      NaN    NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN   NaN      NaN      NaN   NaN    NaN      NaN             71.3400               29.99            71.3400              29.99         0.408073      0.420381  38.3500   -21.61  0.537567 -0.720574\n",
      "2025-12-08 15:41:38       1.77       5.00      1.74       NaN     1.74  1.77     5      AMEX     1.77     5      CBOE        5        5   NaN   NaN      NaN      NaN    NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN   NaN      NaN      NaN   NaN    NaN      NaN             11.9298                0.00            11.9298               0.00         1.000000      0.000000 -31.3202   -70.94 -2.625375       NaN\n",
      "2025-12-08 15:42:09       1.76       6.00      1.74       NaN     1.74  1.76     6 PHLX CBOE     1.76     5 PHLX CBOE       10        4   NaN   NaN      NaN      NaN    NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN   NaN      NaN      NaN   NaN    NaN      NaN             11.8624                0.00            11.8624               0.00         1.000000      0.000000 -41.4576   -35.08 -3.494875       NaN\n",
      "2025-12-08 15:42:26       1.74       1.78      7.00      10.0        7  1.74  1.78        10        7  1.74      1.78        5        2  1.74  1.78        4      NaN    NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN   NaN      NaN      NaN   NaN    NaN      NaN             27.8400               33.82            27.8400              33.82        -0.096983      1.214799 -43.9100    -3.71 -1.577227 -0.109698\n",
      "2025-12-08 15:42:42       1.75       1.77     12.00       8.0       12  1.75  1.77         8        6  1.75      1.77        5       23  1.74  1.79       15      NaN    NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN   NaN      NaN      NaN   NaN    NaN      NaN             71.5200               49.86            71.5200              49.86         0.178448      0.697148  36.9100    23.22  0.516079  0.465704\n",
      "2025-12-08 15:42:57       1.72       1.76     16.00      17.0       16  1.72  1.76        17        7  1.72      1.76        3        3  1.71  1.77       24      NaN    NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN   NaN      NaN      NaN   NaN    NaN      NaN             44.6900               77.68            44.6900              77.68        -0.269592      1.738196  20.3876    77.68  0.456200  1.000000\n",
      "2025-12-08 15:43:13       1.73       1.76      6.00       4.0        6  1.73  1.76         4        2  1.73      1.77       55        2  1.73  1.77       15      NaN    NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN   NaN      NaN      NaN   NaN    NaN      NaN             17.3000              130.94            17.3000             130.94        -0.766595      7.568786 -21.2000    91.88 -1.225434  0.701695\n",
      "2025-12-08 15:43:29       1.74       1.76     18.00      19.0       18  1.74  1.76        19       16  1.74      1.76        5        7  1.74  1.77        7      NaN    NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN    NaN      NaN      NaN   NaN   NaN      NaN      NaN   NaN    NaN      NaN             71.3400               54.63            71.3400              54.63         0.132651      0.765770   1.8800    10.13  0.026353  0.185429\n",
      "\n",
      "Column summary (non-null counts and dtypes):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 47 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   timestamp           800 non-null    object \n",
      " 1   bid_price           800 non-null    float64\n",
      " 2   ask_price           800 non-null    float64\n",
      " 3   bid_size            794 non-null    float64\n",
      " 4   ask_size            780 non-null    float64\n",
      " 5   size_b_1            800 non-null    object \n",
      " 6   bid_1               800 non-null    object \n",
      " 7   ask_1               800 non-null    object \n",
      " 8   size_a_1            799 non-null    object \n",
      " 9   size_b_2            798 non-null    object \n",
      " 10  bid_2               799 non-null    object \n",
      " 11  ask_2               799 non-null    object \n",
      " 12  size_a_2            794 non-null    object \n",
      " 13  size_b_3            796 non-null    object \n",
      " 14  bid_3               779 non-null    object \n",
      " 15  ask_3               779 non-null    object \n",
      " 16  size_a_3            779 non-null    object \n",
      " 17  size_b_4            605 non-null    object \n",
      " 18  bid_4               605 non-null    float64\n",
      " 19  ask_4               605 non-null    float64\n",
      " 20  size_a_4            605 non-null    object \n",
      " 21  size_b_5            604 non-null    object \n",
      " 22  bid_5               605 non-null    object \n",
      " 23  ask_5               605 non-null    float64\n",
      " 24  size_a_5            605 non-null    object \n",
      " 25  size_b_6            604 non-null    object \n",
      " 26  bid_6               605 non-null    object \n",
      " 27  ask_6               605 non-null    float64\n",
      " 28  size_a_6            605 non-null    object \n",
      " 29  size_b_7            604 non-null    object \n",
      " 30  bid_7               604 non-null    object \n",
      " 31  ask_7               604 non-null    object \n",
      " 32  size_a_7            604 non-null    object \n",
      " 33  size_b_8            592 non-null    object \n",
      " 34  bid_8               594 non-null    object \n",
      " 35  ask_8               594 non-null    float64\n",
      " 36  size_a_8            591 non-null    object \n",
      " 37  total_bid_notional  800 non-null    float64\n",
      " 38  total_ask_notional  800 non-null    float64\n",
      " 39  top3_bid_notional   800 non-null    float64\n",
      " 40  top3_ask_notional   800 non-null    float64\n",
      " 41  depth_imbalance     800 non-null    float64\n",
      " 42  ask_bid_walk        800 non-null    float64\n",
      " 43  OFI_bid             800 non-null    float64\n",
      " 44  OFI_ask             800 non-null    float64\n",
      " 45  flow_bid            800 non-null    float64\n",
      " 46  flow_ask            782 non-null    float64\n",
      "dtypes: float64(19), object(28)\n",
      "memory usage: 293.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# CONFIGURATION\n",
    "CLEAN_CSV_FILE = \"2fidelity_orderbook_clean.csv\"\n",
    "POLL_INTERVAL = 1.0\n",
    "MAX_POINTS = 10000\n",
    "OFI_LOOKBACK = 8\n",
    "PICKLE_FILE = \"2imbalance_live.pkl\"  # <---- Added global pickle target\n",
    "\n",
    "print(f\"Starting depth imbalance + normalized OFI monitor (polling every {POLL_INTERVAL}s)\")\n",
    "print(f\"Source: {CLEAN_CSV_FILE}\")\n",
    "print(f\"OFI lookback: {OFI_LOOKBACK} rows, MAX_POINTS: {MAX_POINTS}\")\n",
    "\n",
    "imbalance_df = pd.DataFrame(columns=[\n",
    "    'timestamp', 'depth_imbalance', 'ask_bid_walk',\n",
    "    'OFI_bid', 'OFI_ask', 'flow_bid', 'flow_ask',\n",
    "    'bid_price', 'ask_price', 'bid_size', 'ask_size',\n",
    "    'total_bid_notional', 'total_ask_notional', 'top3_bid_notional', 'top3_ask_notional'\n",
    "])\n",
    "last_file_size = 0\n",
    "\n",
    "\n",
    "def compute_notional_totals(row):\n",
    "    total_bid_notional, total_ask_notional = 0, 0\n",
    "    for lvl in range(1, 11):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            total_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            total_bid_notional += bid_p * bid_s\n",
    "    return total_bid_notional, total_ask_notional\n",
    "\n",
    "\n",
    "def compute_top3_notional(row):\n",
    "    top3_bid_notional, top3_ask_notional = 0, 0\n",
    "    for lvl in range(1, 4):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            top3_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            top3_bid_notional += bid_p * bid_s\n",
    "    return top3_bid_notional, top3_ask_notional\n",
    "\n",
    "\n",
    "print(\"Waiting for clean CSV data...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "\n",
    "        if os.path.exists(CLEAN_CSV_FILE):\n",
    "            current_file_size = os.path.getsize(CLEAN_CSV_FILE)\n",
    "            if current_file_size > last_file_size:\n",
    "                try:\n",
    "                    df_clean = pd.read_csv(CLEAN_CSV_FILE)\n",
    "                    print(f\"Loaded {len(df_clean)} rows from clean CSV\")\n",
    "\n",
    "                    new_rows = df_clean\n",
    "                    new_raw_rows = []\n",
    "                    for _, row in new_rows.iterrows():\n",
    "                        bid_price = pd.to_numeric(row.get('bid_1'), errors='coerce')\n",
    "                        ask_price = pd.to_numeric(row.get('ask_1'), errors='coerce')\n",
    "                        bid_size = pd.to_numeric(row.get('size_b_1'), errors='coerce')\n",
    "                        ask_size = pd.to_numeric(row.get('size_a_1'), errors='coerce')\n",
    "                        if pd.isna(bid_price) or pd.isna(ask_price):\n",
    "                            continue\n",
    "                        new_raw_rows.append({\n",
    "                            'timestamp': row['timestamp'],\n",
    "                            'bid_price': bid_price, 'ask_price': ask_price,\n",
    "                            'bid_size': bid_size, 'ask_size': ask_size,\n",
    "                            **{col: row[col] for col in row.index if col.startswith(('bid_', 'ask_', 'size_'))}\n",
    "                        })\n",
    "\n",
    "                    if new_raw_rows:\n",
    "                        new_df = pd.DataFrame(new_raw_rows)\n",
    "                        existing_timestamps = set(imbalance_df['timestamp'])\n",
    "                        fresh_rows = new_df[~new_df['timestamp'].isin(existing_timestamps)]\n",
    "\n",
    "                        if not fresh_rows.empty:\n",
    "                            if imbalance_df.empty:\n",
    "                                imbalance_df = fresh_rows.copy()\n",
    "                            else:\n",
    "                                imbalance_df = pd.concat([imbalance_df, fresh_rows], ignore_index=True)\n",
    "\n",
    "                            if len(imbalance_df) > MAX_POINTS:\n",
    "                                imbalance_df = imbalance_df.tail(MAX_POINTS).reset_index(drop=True)\n",
    "\n",
    "                            print(f\"\\n--- RECOMPUTING METRICS ON {len(imbalance_df)} rows ---\")\n",
    "                            for i in range(len(imbalance_df)):\n",
    "                                row = imbalance_df.iloc[i]\n",
    "                                total_bid_n, total_ask_n = compute_notional_totals(row)\n",
    "                                top3_bid_n, top3_ask_n = compute_top3_notional(row)\n",
    "\n",
    "                                imbalance_df.loc[i, 'total_bid_notional'] = total_bid_n\n",
    "                                imbalance_df.loc[i, 'total_ask_notional'] = total_ask_n\n",
    "                                imbalance_df.loc[i, 'top3_bid_notional'] = top3_bid_n\n",
    "                                imbalance_df.loc[i, 'top3_ask_notional'] = top3_ask_n\n",
    "\n",
    "                                denom = total_bid_n + total_ask_n\n",
    "                                imb = (total_bid_n - total_ask_n) / denom if denom != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'depth_imbalance'] = imb\n",
    "\n",
    "                                ask_bid_walk = top3_ask_n / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'ask_bid_walk'] = ask_bid_walk\n",
    "\n",
    "                                ofi_bid, ofi_ask = 0, 0\n",
    "                                if i >= OFI_LOOKBACK:\n",
    "                                    p_idx = i - OFI_LOOKBACK\n",
    "                                    prior_bid_n = imbalance_df.loc[p_idx, 'total_bid_notional']\n",
    "                                    prior_ask_n = imbalance_df.loc[p_idx, 'total_ask_notional']\n",
    "                                    ofi_bid = total_bid_n - prior_bid_n\n",
    "                                    ofi_ask = total_ask_n - prior_ask_n\n",
    "                                imbalance_df.loc[i, 'OFI_bid'] = ofi_bid\n",
    "                                imbalance_df.loc[i, 'OFI_ask'] = ofi_ask\n",
    "\n",
    "                                flow_bid = ofi_bid / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                flow_ask = ofi_ask / top3_ask_n if top3_ask_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'flow_bid'] = flow_bid\n",
    "                                imbalance_df.loc[i, 'flow_ask'] = flow_ask\n",
    "\n",
    "                            # Save to pickle for other kernels\n",
    "                            imbalance_df.to_pickle(PICKLE_FILE)\n",
    "                            print(f\"Updated pickle: {PICKLE_FILE}\")\n",
    "\n",
    "                            latest = imbalance_df.iloc[-1]\n",
    "                            print(f\"[{latest['timestamp']}] Imb:{latest['depth_imbalance']:.3f} \"\n",
    "                                  f\"W:{latest['ask_bid_walk']:.2f} F_B:{latest['flow_bid']:.3f} F_A:{latest['flow_ask']:.3f}\")\n",
    "\n",
    "                    last_file_size = current_file_size\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Processing error: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Clean CSV not found yet, waiting...\")\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        time.sleep(max(0, POLL_INTERVAL - elapsed))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped by user\")\n",
    "\n",
    "    if not imbalance_df.empty:\n",
    "        # Save final snapshot\n",
    "        imbalance_df.to_pickle(PICKLE_FILE)\n",
    "        print(f\"Saved final snapshot to {PICKLE_FILE}\")\n",
    "        \n",
    "        # Print final dataframe info\n",
    "        print(f\"\\nFinal DataFrame shape: {imbalance_df.shape}\")\n",
    "        print(\"\\nLatest 10 rows of final data:\")\n",
    "        print(imbalance_df.tail(10).to_string(index=False))\n",
    "\n",
    "        # Optional: print data summary\n",
    "        print(\"\\nColumn summary (non-null counts and dtypes):\")\n",
    "        print(imbalance_df.info())\n",
    "    else:\n",
    "        print(\"No data captured — imbalance_df is empty.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
