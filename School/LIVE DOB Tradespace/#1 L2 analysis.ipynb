{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f3b748",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2101194239.py, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 25\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\"Compute total bid/ask notional for a single row (10 levels)\"\"\"\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# CONFIGURATION\n",
    "CLEAN_CSV_FILE = \"fidelity_orderbook_clean.csv\"\n",
    "POLL_INTERVAL = 1.0\n",
    "MAX_POINTS = 10000\n",
    "OFI_LOOKBACK = 8\n",
    "\n",
    "print(f\"Starting depth imbalance + normalized OFI monitor (polling every {POLL_INTERVAL}s)\")\n",
    "print(f\"Source: {CLEAN_CSV_FILE}\")\n",
    "print(f\"OFI lookback: {OFI_LOOKBACK} rows, MAX_POINTS: {MAX_POINTS}\")\n",
    "\n",
    "imbalance_df = pd.DataFrame(columns=[\n",
    "    'timestamp', 'depth_imbalance', 'ask_bid_walk',\n",
    "    'OFI_bid', 'OFI_ask', 'flow_bid', 'flow_ask',\n",
    "    'bid_price', 'ask_price', 'bid_size', 'ask_size',\n",
    "    'total_bid_notional', 'total_ask_notional', 'top3_bid_notional', 'top3_ask_notional'\n",
    "])\n",
    "last_file_size = 0\n",
    "\n",
    "def compute_notional_totals(row):\n",
    "    \"\"\"Compute total bid/ask notional for a single row (10 levels)\"\"\"\n",
    "    total_bid_notional = 0\n",
    "    total_ask_notional = 0\n",
    "    \n",
    "    for lvl in range(1, 11):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        \n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            total_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            total_bid_notional += bid_p * bid_s\n",
    "    \n",
    "    return total_bid_notional, total_ask_notional\n",
    "\n",
    "def compute_top3_notional(row):\n",
    "    \"\"\"Compute top-3 bid/ask notional for normalization\"\"\"\n",
    "    top3_bid_notional = 0\n",
    "    top3_ask_notional = 0\n",
    "    \n",
    "    for lvl in range(1, 4):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        \n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            top3_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            top3_bid_notional += bid_p * bid_s\n",
    "    \n",
    "    return top3_bid_notional, top3_ask_notional\n",
    "\n",
    "print(\"Waiting for clean CSV data...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "\n",
    "        if os.path.exists(CLEAN_CSV_FILE):\n",
    "            current_file_size = os.path.getsize(CLEAN_CSV_FILE)\n",
    "\n",
    "            if current_file_size > last_file_size:\n",
    "                try:\n",
    "                    df_clean = pd.read_csv(CLEAN_CSV_FILE)\n",
    "                    print(f\"Loaded {len(df_clean)} rows from clean CSV\")\n",
    "\n",
    "                    # *** FIXED: Process ALL rows, not just tail(10) ***\n",
    "                    new_rows = df_clean  # ← ALL ROWS!\n",
    "                    new_raw_rows = []\n",
    "\n",
    "                    for _, row in new_rows.iterrows():\n",
    "                        bid_price = pd.to_numeric(row.get('bid_1'), errors='coerce')\n",
    "                        ask_price = pd.to_numeric(row.get('ask_1'), errors='coerce')\n",
    "                        bid_size = pd.to_numeric(row.get('size_b_1'), errors='coerce')\n",
    "                        ask_size = pd.to_numeric(row.get('size_a_1'), errors='coerce')\n",
    "                        \n",
    "                        if pd.isna(bid_price) or pd.isna(ask_price):\n",
    "                            continue\n",
    "                            \n",
    "                        new_raw_rows.append({\n",
    "                            'timestamp': row['timestamp'],\n",
    "                            'bid_price': bid_price, 'ask_price': ask_price,\n",
    "                            'bid_size': bid_size, 'ask_size': ask_size,\n",
    "                            **{col: row[col] for col in row.index if col.startswith(('bid_', 'ask_', 'size_'))}\n",
    "                        })\n",
    "\n",
    "                    # Add new raw data to imbalance_df\n",
    "                    if new_raw_rows:\n",
    "                        new_df = pd.DataFrame(new_raw_rows)\n",
    "                        existing_timestamps = set(imbalance_df['timestamp'])\n",
    "                        fresh_rows = new_df[~new_df['timestamp'].isin(existing_timestamps)]\n",
    "\n",
    "                        print(f\"Found {len(fresh_rows)} NEW rows to add (total will be {len(imbalance_df) + len(fresh_rows)})\")\n",
    "\n",
    "                        if not fresh_rows.empty:\n",
    "                            if imbalance_df.empty:\n",
    "                                imbalance_df = fresh_rows.copy()\n",
    "                            else:\n",
    "                                imbalance_df = pd.concat([imbalance_df, fresh_rows], ignore_index=True)\n",
    "\n",
    "                            # Trim to MAX_POINTS\n",
    "                            if len(imbalance_df) > MAX_POINTS:\n",
    "                                imbalance_df = imbalance_df.tail(MAX_POINTS).reset_index(drop=True)\n",
    "\n",
    "                            # RECOMPUTE ALL METRICS ON FULL MAX_POINTS DATA\n",
    "                            print(f\"\\n--- RECOMPUTING METRICS ON {len(imbalance_df)} rows ---\")\n",
    "                            for i in range(len(imbalance_df)):\n",
    "                                row = imbalance_df.iloc[i]\n",
    "                                \n",
    "                                total_bid_n, total_ask_n = compute_notional_totals(row)\n",
    "                                top3_bid_n, top3_ask_n = compute_top3_notional(row)\n",
    "                                \n",
    "                                imbalance_df.loc[i, 'total_bid_notional'] = total_bid_n\n",
    "                                imbalance_df.loc[i, 'total_ask_notional'] = total_ask_n\n",
    "                                imbalance_df.loc[i, 'top3_bid_notional'] = top3_bid_n\n",
    "                                imbalance_df.loc[i, 'top3_ask_notional'] = top3_ask_n\n",
    "                                \n",
    "                                denom = total_bid_n + total_ask_n\n",
    "                                depth_imbalance = (total_bid_n - total_ask_n) / denom if denom != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'depth_imbalance'] = depth_imbalance\n",
    "                                \n",
    "                                ask_bid_walk = top3_ask_n / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'ask_bid_walk'] = ask_bid_walk\n",
    "                                \n",
    "                                ofi_bid, ofi_ask = 0, 0\n",
    "                                if i >= OFI_LOOKBACK:\n",
    "                                    prior_idx = i - OFI_LOOKBACK\n",
    "                                    prior_bid_n = imbalance_df.loc[prior_idx, 'total_bid_notional']\n",
    "                                    prior_ask_n = imbalance_df.loc[prior_idx, 'total_ask_notional']\n",
    "                                    ofi_bid = total_bid_n - prior_bid_n\n",
    "                                    ofi_ask = total_ask_n - prior_ask_n\n",
    "                                imbalance_df.loc[i, 'OFI_bid'] = ofi_bid\n",
    "                                imbalance_df.loc[i, 'OFI_ask'] = ofi_ask\n",
    "                                \n",
    "                                flow_bid = ofi_bid / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                flow_ask = ofi_ask / top3_ask_n if top3_ask_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'flow_bid'] = flow_bid\n",
    "                                imbalance_df.loc[i, 'flow_ask'] = flow_ask\n",
    "\n",
    "                            latest = imbalance_df.iloc[-1]\n",
    "                            print(f\"[{latest['timestamp']}] Imb:{latest['depth_imbalance']:.3f} W:{latest['ask_bid_walk']:.2f} \"\n",
    "                                  f\"OFI_B:${latest['OFI_bid']:,.0f} OFI_A:${latest['OFI_ask']:,.0f} \"\n",
    "                                  f\"F_B:{latest['flow_bid']:.3f} F_A:{latest['flow_ask']:.3f} \"\n",
    "                                  f\"B1:${latest['bid_price']:.2f}x{int(latest['bid_size'])} \"\n",
    "                                  f\"A1:${latest['ask_price']:.2f}x{int(latest['ask_size'])} \"\n",
    "                                  f\"({len(imbalance_df)} rows)\")\n",
    "\n",
    "                    last_file_size = current_file_size\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Processing error: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Clean CSV not found yet, waiting...\")\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        sleep_time = max(0, POLL_INTERVAL - elapsed)\n",
    "        if sleep_time > 0:\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped by user\")\n",
    "    print(f\"Final DataFrame shape: {imbalance_df.shape}\")\n",
    "    if not imbalance_df.empty:\n",
    "        print(\"\\nLatest 5 rows:\")\n",
    "        print(imbalance_df[['timestamp', 'depth_imbalance', 'ask_bid_walk', 'OFI_bid', 'OFI_ask', \n",
    "                           'flow_bid', 'flow_ask', 'bid_price', 'ask_price']].tail())\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8627968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting depth imbalance + normalized OFI monitor (polling every 1.0s)\n",
      "Source: fidelity_orderbook_clean.csv\n",
      "OFI lookback: 8 rows, MAX_POINTS: 10000\n",
      "Waiting for clean CSV data...\n",
      "Loaded 2074 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 2066 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-09 12:44:09] Imb:-0.076 W:1.36 F_B:0.111 F_A:0.454\n",
      "Loaded 2075 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 2067 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-09 12:44:32] Imb:-0.553 W:6.00 F_B:0.318 F_A:1.167\n",
      "Loaded 2076 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 2068 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-09 12:44:39] Imb:0.314 W:0.43 F_B:-0.100 F_A:-0.397\n",
      "Loaded 2077 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 2069 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-09 12:45:01] Imb:-0.586 W:1.29 F_B:0.276 F_A:11.572\n",
      "Loaded 2078 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 2070 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-09 12:45:09] Imb:-0.101 W:0.97 F_B:0.150 F_A:0.531\n",
      "Loaded 2079 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 2071 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-09 12:45:30] Imb:-0.149 W:1.17 F_B:0.579 F_A:0.260\n",
      "Loaded 2080 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 2072 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-09 12:45:37] Imb:-0.211 W:1.57 F_B:-15.040 F_A:-3.069\n",
      "Loaded 2081 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 2073 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-09 12:45:58] Imb:0.130 W:0.32 F_B:0.832 F_A:2.115\n",
      "Loaded 2082 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 2074 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-09 12:46:04] Imb:0.639 W:0.09 F_B:1.216 F_A:-0.230\n",
      "Loaded 2083 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 2075 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-09 12:46:25] Imb:0.234 W:0.45 F_B:1.044 F_A:-1.414\n",
      "Loaded 2084 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 2076 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-09 12:46:31] Imb:-0.610 W:1.54 F_B:-0.752 F_A:2.477\n",
      "Loaded 2085 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 2077 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-09 12:46:52] Imb:0.525 W:1.22 F_B:2.501 F_A:-7.702\n",
      "Loaded 2086 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 2078 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-09 12:46:58] Imb:-0.307 W:7.65 F_B:-4.133 F_A:-0.258\n",
      "\n",
      "Stopped by user\n",
      "Saved final snapshot to imbalance_live.pkl\n",
      "\n",
      "Final DataFrame shape: (2078, 59)\n",
      "\n",
      "Latest 10 rows of final data:\n",
      "          timestamp  bid_price  ask_price  bid_size  ask_size size_b_1  bid_1  ask_1 size_a_1 size_b_2  bid_2  ask_2 size_a_2 size_b_3  bid_3  ask_3 size_a_3 size_b_4  bid_4  ask_4 size_a_4 size_b_5  bid_5  ask_5 size_a_5 size_b_6  bid_6  ask_6 size_a_6 size_b_7  bid_7  ask_7 size_a_7 size_b_8  bid_8  ask_8 size_a_8 size_b_9  bid_9  ask_9 size_a_9 size_b_10  bid_10  ask_10 size_a_10 size_b_11  bid_11  ask_11 size_a_11  total_bid_notional  total_ask_notional  top3_bid_notional  top3_ask_notional  depth_imbalance  ask_bid_walk    OFI_bid    OFI_ask   flow_bid  flow_ask\n",
      "2025-12-09 12:45:01     450.46     450.50      80.0      80.0     80.0 450.46  450.5     80.0     13.0 450.46  450.5      6.0      5.0  450.4  450.5     40.0    120.0 450.39 450.53    400.0      2.0 450.38 450.54      4.0      2.0 450.36 450.55     80.0      2.0 450.34 450.55    880.0      2.0 450.32 450.55     80.0    120.0 450.31 450.56     20.0      80.0  450.31  450.57      42.0       NaN     NaN     NaN       NaN           191856.38           735284.30           44144.78           56763.00        -0.586133      1.285837   12171.48  656888.10   0.275717 11.572470\n",
      "2025-12-09 12:45:09     450.42     450.47     400.0      80.0      400 450.42 450.47       80       40 450.41 450.48      123       80 450.39 450.49      300        2 450.34 450.50      280        2 450.32 450.50       40      120 450.31 450.51        3       80 450.31 450.54        8       29 450.30 450.55        2        9 450.28 450.56       60         3  450.27  450.56        40       NaN     NaN     NaN       NaN           344540.95           421666.59          234215.60          226593.64        -0.100659      0.967458   35174.64  120360.52   0.150181  0.531173\n",
      "2025-12-09 12:45:30     450.39     450.41      80.0     120.0       80 450.39 450.41      120       80 450.38 450.41       40       11 450.37 450.43       40        9 450.34 450.43       36      120 450.31 450.44        9       80 450.31 450.46       80       80 450.31 450.48       20       29 450.30 450.49      327        9 450.28 450.51        2         3  450.27  450.53         2       NaN     NaN     NaN       NaN           225617.56           304510.95           77015.67           90082.80        -0.148819      1.169668   44588.97   23424.96   0.578960  0.260038\n",
      "2025-12-09 12:45:37     450.38     450.41      80.0     120.0       80 450.38 450.41      120       40 450.38 450.41       40       20 450.38 450.41       60      128 450.31 450.42        9       80 450.31 450.43       36       29 450.30 450.44        9        9 450.28 450.45        1        3 450.27 450.48       20        2 450.26 450.49      320        11  450.25  450.51         2       NaN     NaN     NaN       NaN           181032.98           277931.29           63053.20           99090.20        -0.211124      1.571533 -948289.71 -304083.27 -15.039518 -3.068752\n",
      "2025-12-09 12:45:58     450.43     450.45     120.0      80.0      120 450.43 450.45       80      120 450.41 450.45       40      380 450.40 450.46       80        6 450.35 450.46       40        2 450.34 450.48       10        3 450.33 450.49      334       12 450.32 450.50        1      120 450.31 450.52       80       80 450.31 450.54        4        29  450.30  450.55         2       NaN     NaN     NaN       NaN           392731.11           302273.02          279252.80           90090.80         0.130155      0.322614  232412.60  190544.30   0.832266  2.115025\n",
      "2025-12-09 12:46:04     450.30     450.32     440.0      46.0      440 450.30 450.32       46      560 450.30 450.33       40       13 450.28 450.33        6       28 450.27 450.33       80       80 450.26 450.34        6      200 450.26 450.35       80       11 450.25 450.36       20      200 450.23 450.40       40        2 450.22 450.42        1         7  450.20  450.43        20       NaN     NaN     NaN       NaN           693884.59           152668.56          456153.64           41429.90         0.639317      0.090824  554717.98   -9516.67   1.216077 -0.229705\n",
      "2025-12-09 12:46:25     450.25     450.28     160.0      12.0      160 450.25 450.28       12      200 450.24 450.28      160      200 450.24 450.31       80      206 450.23 450.32       60        5 450.20 450.33      160       27 450.18 450.37        2        2 450.16 450.39        2       10 450.15 450.41        2        2 450.14 450.43        2        25  450.13  450.44        40       NaN     NaN     NaN       NaN           376844.59           234165.76          252136.00          113472.96         0.233513      0.450047  263354.29 -160479.50   1.044493 -1.414253\n",
      "2025-12-09 12:46:31     450.25     450.29      40.0     160.0       40 450.25 450.29      160      206 450.23 450.29      200       40 450.23 450.32       80        5  450.2 450.36      880        1 450.19 450.39        2       27 450.18 450.41        2        2 450.16 450.43        2       10 450.15 450.44       10        2 450.14 450.44       40       NaN     NaN     NaN       NaN       NaN     NaN     NaN       NaN           149924.73           619671.26          128766.58          198130.00        -0.610381      1.538676  -96852.74  490845.45  -0.752157  2.477391\n",
      "2025-12-09 12:46:52     450.08     450.11      80.0      40.0       80 450.08 450.11       40       42 450.05 450.11       60       25 450.03 450.18       80      127 450.02 450.19        8      200 450.01 450.21        2      200 450.00 450.23        2       90 450.00 450.25        2        1 449.99 450.26       40       27 449.98 450.27        2         2  449.96  450.29        11       NaN     NaN     NaN       NaN           357313.16           111192.43           66159.25           81025.40         0.525331      1.224703  165456.78 -624091.87   2.500887 -7.702423\n",
      "2025-12-09 12:46:58     450.14     450.18      40.0     600.0       40 450.14 450.18      600        7 450.06 450.18       40       40 450.06 450.19       25       42 450.05 450.21       20        2 450.04 450.23       40       25 450.03 450.25        2      129 450.02 450.27       22       40 450.00 450.29        2       80 450.00 450.30       12         1  449.99  450.31         2       NaN     NaN     NaN       NaN           182713.92           344394.59           39158.42          299369.95        -0.306731      7.645098 -161827.03  -77272.00  -4.132624 -0.258115\n",
      "\n",
      "Column summary (non-null counts and dtypes):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2078 entries, 0 to 2077\n",
      "Data columns (total 59 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   timestamp           2078 non-null   object \n",
      " 1   bid_price           2078 non-null   float64\n",
      " 2   ask_price           2078 non-null   float64\n",
      " 3   bid_size            2078 non-null   float64\n",
      " 4   ask_size            2077 non-null   float64\n",
      " 5   size_b_1            2078 non-null   object \n",
      " 6   bid_1               2078 non-null   object \n",
      " 7   ask_1               2078 non-null   object \n",
      " 8   size_a_1            2078 non-null   object \n",
      " 9   size_b_2            2075 non-null   object \n",
      " 10  bid_2               2076 non-null   object \n",
      " 11  ask_2               2077 non-null   object \n",
      " 12  size_a_2            2076 non-null   object \n",
      " 13  size_b_3            2077 non-null   object \n",
      " 14  bid_3               2077 non-null   object \n",
      " 15  ask_3               2075 non-null   object \n",
      " 16  size_a_3            2078 non-null   object \n",
      " 17  size_b_4            2078 non-null   object \n",
      " 18  bid_4               2078 non-null   object \n",
      " 19  ask_4               2078 non-null   object \n",
      " 20  size_a_4            2078 non-null   object \n",
      " 21  size_b_5            2078 non-null   object \n",
      " 22  bid_5               2078 non-null   object \n",
      " 23  ask_5               2078 non-null   object \n",
      " 24  size_a_5            2078 non-null   object \n",
      " 25  size_b_6            2078 non-null   object \n",
      " 26  bid_6               2078 non-null   object \n",
      " 27  ask_6               2078 non-null   object \n",
      " 28  size_a_6            2078 non-null   object \n",
      " 29  size_b_7            2078 non-null   object \n",
      " 30  bid_7               2078 non-null   object \n",
      " 31  ask_7               2078 non-null   float64\n",
      " 32  size_a_7            2078 non-null   object \n",
      " 33  size_b_8            2078 non-null   object \n",
      " 34  bid_8               2078 non-null   float64\n",
      " 35  ask_8               2078 non-null   float64\n",
      " 36  size_a_8            2078 non-null   object \n",
      " 37  size_b_9            2061 non-null   object \n",
      " 38  bid_9               2061 non-null   float64\n",
      " 39  ask_9               2061 non-null   float64\n",
      " 40  size_a_9            2061 non-null   object \n",
      " 41  size_b_10           1883 non-null   object \n",
      " 42  bid_10              1883 non-null   float64\n",
      " 43  ask_10              1883 non-null   float64\n",
      " 44  size_a_10           1883 non-null   object \n",
      " 45  size_b_11           378 non-null    object \n",
      " 46  bid_11              381 non-null    float64\n",
      " 47  ask_11              380 non-null    float64\n",
      " 48  size_a_11           376 non-null    object \n",
      " 49  total_bid_notional  2078 non-null   float64\n",
      " 50  total_ask_notional  2078 non-null   float64\n",
      " 51  top3_bid_notional   2078 non-null   float64\n",
      " 52  top3_ask_notional   2078 non-null   float64\n",
      " 53  depth_imbalance     2078 non-null   float64\n",
      " 54  ask_bid_walk        2078 non-null   float64\n",
      " 55  OFI_bid             2078 non-null   float64\n",
      " 56  OFI_ask             2078 non-null   float64\n",
      " 57  flow_bid            2078 non-null   float64\n",
      " 58  flow_ask            2078 non-null   float64\n",
      "dtypes: float64(23), object(36)\n",
      "memory usage: 958.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# CONFIGURATION\n",
    "CLEAN_CSV_FILE = \"fidelity_orderbook_clean.csv\"\n",
    "POLL_INTERVAL = 1.0\n",
    "MAX_POINTS = 10000\n",
    "OFI_LOOKBACK = 8\n",
    "PICKLE_FILE = \"imbalance_live.pkl\"  # <---- Added global pickle target\n",
    "\n",
    "print(f\"Starting depth imbalance + normalized OFI monitor (polling every {POLL_INTERVAL}s)\")\n",
    "print(f\"Source: {CLEAN_CSV_FILE}\")\n",
    "print(f\"OFI lookback: {OFI_LOOKBACK} rows, MAX_POINTS: {MAX_POINTS}\")\n",
    "\n",
    "imbalance_df = pd.DataFrame(columns=[\n",
    "    'timestamp', 'depth_imbalance', 'ask_bid_walk',\n",
    "    'OFI_bid', 'OFI_ask', 'flow_bid', 'flow_ask',\n",
    "    'bid_price', 'ask_price', 'bid_size', 'ask_size',\n",
    "    'total_bid_notional', 'total_ask_notional', 'top3_bid_notional', 'top3_ask_notional'\n",
    "])\n",
    "last_file_size = 0\n",
    "\n",
    "\n",
    "def compute_notional_totals(row):\n",
    "    total_bid_notional, total_ask_notional = 0, 0\n",
    "    for lvl in range(1, 11):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            total_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            total_bid_notional += bid_p * bid_s\n",
    "    return total_bid_notional, total_ask_notional\n",
    "\n",
    "\n",
    "def compute_top3_notional(row):\n",
    "    top3_bid_notional, top3_ask_notional = 0, 0\n",
    "    for lvl in range(1, 4):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            top3_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            top3_bid_notional += bid_p * bid_s\n",
    "    return top3_bid_notional, top3_ask_notional\n",
    "\n",
    "\n",
    "print(\"Waiting for clean CSV data...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "\n",
    "        if os.path.exists(CLEAN_CSV_FILE):\n",
    "            current_file_size = os.path.getsize(CLEAN_CSV_FILE)\n",
    "            if current_file_size > last_file_size:\n",
    "                try:\n",
    "                    df_clean = pd.read_csv(CLEAN_CSV_FILE)\n",
    "                    print(f\"Loaded {len(df_clean)} rows from clean CSV\")\n",
    "\n",
    "                    new_rows = df_clean\n",
    "                    new_raw_rows = []\n",
    "                    for _, row in new_rows.iterrows():\n",
    "                        bid_price = pd.to_numeric(row.get('bid_1'), errors='coerce')\n",
    "                        ask_price = pd.to_numeric(row.get('ask_1'), errors='coerce')\n",
    "                        bid_size = pd.to_numeric(row.get('size_b_1'), errors='coerce')\n",
    "                        ask_size = pd.to_numeric(row.get('size_a_1'), errors='coerce')\n",
    "                        if pd.isna(bid_price) or pd.isna(ask_price):\n",
    "                            continue\n",
    "                        new_raw_rows.append({\n",
    "                            'timestamp': row['timestamp'],\n",
    "                            'bid_price': bid_price, 'ask_price': ask_price,\n",
    "                            'bid_size': bid_size, 'ask_size': ask_size,\n",
    "                            **{col: row[col] for col in row.index if col.startswith(('bid_', 'ask_', 'size_'))}\n",
    "                        })\n",
    "\n",
    "                    if new_raw_rows:\n",
    "                        new_df = pd.DataFrame(new_raw_rows)\n",
    "                        existing_timestamps = set(imbalance_df['timestamp'])\n",
    "                        fresh_rows = new_df[~new_df['timestamp'].isin(existing_timestamps)]\n",
    "\n",
    "                        if not fresh_rows.empty:\n",
    "                            if imbalance_df.empty:\n",
    "                                imbalance_df = fresh_rows.copy()\n",
    "                            else:\n",
    "                                imbalance_df = pd.concat([imbalance_df, fresh_rows], ignore_index=True)\n",
    "\n",
    "                            if len(imbalance_df) > MAX_POINTS:\n",
    "                                imbalance_df = imbalance_df.tail(MAX_POINTS).reset_index(drop=True)\n",
    "\n",
    "                            print(f\"\\n--- RECOMPUTING METRICS ON {len(imbalance_df)} rows ---\")\n",
    "                            for i in range(len(imbalance_df)):\n",
    "                                row = imbalance_df.iloc[i]\n",
    "                                total_bid_n, total_ask_n = compute_notional_totals(row)\n",
    "                                top3_bid_n, top3_ask_n = compute_top3_notional(row)\n",
    "\n",
    "                                imbalance_df.loc[i, 'total_bid_notional'] = total_bid_n\n",
    "                                imbalance_df.loc[i, 'total_ask_notional'] = total_ask_n\n",
    "                                imbalance_df.loc[i, 'top3_bid_notional'] = top3_bid_n\n",
    "                                imbalance_df.loc[i, 'top3_ask_notional'] = top3_ask_n\n",
    "\n",
    "                                denom = total_bid_n + total_ask_n\n",
    "                                imb = (total_bid_n - total_ask_n) / denom if denom != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'depth_imbalance'] = imb\n",
    "\n",
    "                                ask_bid_walk = top3_ask_n / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'ask_bid_walk'] = ask_bid_walk\n",
    "\n",
    "                                ofi_bid, ofi_ask = 0, 0\n",
    "                                if i >= OFI_LOOKBACK:\n",
    "                                    p_idx = i - OFI_LOOKBACK\n",
    "                                    prior_bid_n = imbalance_df.loc[p_idx, 'total_bid_notional']\n",
    "                                    prior_ask_n = imbalance_df.loc[p_idx, 'total_ask_notional']\n",
    "                                    ofi_bid = total_bid_n - prior_bid_n\n",
    "                                    ofi_ask = total_ask_n - prior_ask_n\n",
    "                                imbalance_df.loc[i, 'OFI_bid'] = ofi_bid\n",
    "                                imbalance_df.loc[i, 'OFI_ask'] = ofi_ask\n",
    "\n",
    "                                flow_bid = ofi_bid / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                flow_ask = ofi_ask / top3_ask_n if top3_ask_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'flow_bid'] = flow_bid\n",
    "                                imbalance_df.loc[i, 'flow_ask'] = flow_ask\n",
    "\n",
    "                            # Save to pickle for other kernels\n",
    "                            imbalance_df.to_pickle(PICKLE_FILE)\n",
    "                            print(f\"Updated pickle: {PICKLE_FILE}\")\n",
    "\n",
    "                            latest = imbalance_df.iloc[-1]\n",
    "                            print(f\"[{latest['timestamp']}] Imb:{latest['depth_imbalance']:.3f} \"\n",
    "                                  f\"W:{latest['ask_bid_walk']:.2f} F_B:{latest['flow_bid']:.3f} F_A:{latest['flow_ask']:.3f}\")\n",
    "\n",
    "                    last_file_size = current_file_size\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Processing error: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Clean CSV not found yet, waiting...\")\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        time.sleep(max(0, POLL_INTERVAL - elapsed))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped by user\")\n",
    "\n",
    "    if not imbalance_df.empty:\n",
    "        # Save final snapshot\n",
    "        imbalance_df.to_pickle(PICKLE_FILE)\n",
    "        print(f\"Saved final snapshot to {PICKLE_FILE}\")\n",
    "        \n",
    "        # Print final dataframe info\n",
    "        print(f\"\\nFinal DataFrame shape: {imbalance_df.shape}\")\n",
    "        print(\"\\nLatest 10 rows of final data:\")\n",
    "        print(imbalance_df.tail(10).to_string(index=False))\n",
    "\n",
    "        # Optional: print data summary\n",
    "        print(\"\\nColumn summary (non-null counts and dtypes):\")\n",
    "        print(imbalance_df.info())\n",
    "    else:\n",
    "        print(\"No data captured — imbalance_df is empty.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
