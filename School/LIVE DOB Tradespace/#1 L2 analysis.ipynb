{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f3b748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting depth imbalance + normalized OFI monitor (polling every 1.0s)\n",
      "Source: fidelity_orderbook_clean.csv\n",
      "OFI lookback: 8 rows, MAX_POINTS: 10000\n",
      "Waiting for clean CSV data...\n",
      "Loaded 533 rows from clean CSV\n",
      "Found 532 NEW rows to add (total will be 532)\n",
      "\n",
      "--- RECOMPUTING METRICS ON 532 rows ---\n",
      "[2025-12-06 12:18:41] Imb:-0.655 W:50.11 OFI_B:$0 OFI_A:$0 F_B:0.000 F_A:0.000 B1:$454.61x1 A1:$454.64x160 (532 rows)\n",
      "\n",
      "Stopped by user\n",
      "Final DataFrame shape: (532, 59)\n",
      "\n",
      "Latest 5 rows:\n",
      "               timestamp  depth_imbalance  ask_bid_walk  OFI_bid  OFI_ask  \\\n",
      "527  2025-12-06 11:57:03        -0.654939     50.110598      0.0      0.0   \n",
      "528  2025-12-06 12:18:17        -0.654939     50.110598      0.0      0.0   \n",
      "529  2025-12-06 12:18:24        -0.654939     50.110598      0.0      0.0   \n",
      "530  2025-12-06 12:18:32        -0.654939     50.110598      0.0      0.0   \n",
      "531  2025-12-06 12:18:41        -0.654939     50.110598      0.0      0.0   \n",
      "\n",
      "     flow_bid  flow_ask  bid_price  ask_price  \n",
      "527       0.0       0.0     454.61     454.64  \n",
      "528       0.0       0.0     454.61     454.64  \n",
      "529       0.0       0.0     454.61     454.64  \n",
      "530       0.0       0.0     454.61     454.64  \n",
      "531       0.0       0.0     454.61     454.64  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# CONFIGURATION\n",
    "CLEAN_CSV_FILE = \"fidelity_orderbook_clean.csv\"\n",
    "POLL_INTERVAL = 1.0\n",
    "MAX_POINTS = 10000\n",
    "OFI_LOOKBACK = 8\n",
    "\n",
    "print(f\"Starting depth imbalance + normalized OFI monitor (polling every {POLL_INTERVAL}s)\")\n",
    "print(f\"Source: {CLEAN_CSV_FILE}\")\n",
    "print(f\"OFI lookback: {OFI_LOOKBACK} rows, MAX_POINTS: {MAX_POINTS}\")\n",
    "\n",
    "imbalance_df = pd.DataFrame(columns=[\n",
    "    'timestamp', 'depth_imbalance', 'ask_bid_walk',\n",
    "    'OFI_bid', 'OFI_ask', 'flow_bid', 'flow_ask',\n",
    "    'bid_price', 'ask_price', 'bid_size', 'ask_size',\n",
    "    'total_bid_notional', 'total_ask_notional', 'top3_bid_notional', 'top3_ask_notional'\n",
    "])\n",
    "last_file_size = 0\n",
    "\n",
    "def compute_notional_totals(row):\n",
    "    \"\"\"Compute total bid/ask notional for a single row (10 levels)\"\"\"\n",
    "    total_bid_notional = 0\n",
    "    total_ask_notional = 0\n",
    "    \n",
    "    for lvl in range(1, 11):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        \n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            total_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            total_bid_notional += bid_p * bid_s\n",
    "    \n",
    "    return total_bid_notional, total_ask_notional\n",
    "\n",
    "def compute_top3_notional(row):\n",
    "    \"\"\"Compute top-3 bid/ask notional for normalization\"\"\"\n",
    "    top3_bid_notional = 0\n",
    "    top3_ask_notional = 0\n",
    "    \n",
    "    for lvl in range(1, 4):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        \n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            top3_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            top3_bid_notional += bid_p * bid_s\n",
    "    \n",
    "    return top3_bid_notional, top3_ask_notional\n",
    "\n",
    "print(\"Waiting for clean CSV data...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "\n",
    "        if os.path.exists(CLEAN_CSV_FILE):\n",
    "            current_file_size = os.path.getsize(CLEAN_CSV_FILE)\n",
    "\n",
    "            if current_file_size > last_file_size:\n",
    "                try:\n",
    "                    df_clean = pd.read_csv(CLEAN_CSV_FILE)\n",
    "                    print(f\"Loaded {len(df_clean)} rows from clean CSV\")\n",
    "\n",
    "                    # *** FIXED: Process ALL rows, not just tail(10) ***\n",
    "                    new_rows = df_clean  # ← ALL ROWS!\n",
    "                    new_raw_rows = []\n",
    "\n",
    "                    for _, row in new_rows.iterrows():\n",
    "                        bid_price = pd.to_numeric(row.get('bid_1'), errors='coerce')\n",
    "                        ask_price = pd.to_numeric(row.get('ask_1'), errors='coerce')\n",
    "                        bid_size = pd.to_numeric(row.get('size_b_1'), errors='coerce')\n",
    "                        ask_size = pd.to_numeric(row.get('size_a_1'), errors='coerce')\n",
    "                        \n",
    "                        if pd.isna(bid_price) or pd.isna(ask_price):\n",
    "                            continue\n",
    "                            \n",
    "                        new_raw_rows.append({\n",
    "                            'timestamp': row['timestamp'],\n",
    "                            'bid_price': bid_price, 'ask_price': ask_price,\n",
    "                            'bid_size': bid_size, 'ask_size': ask_size,\n",
    "                            **{col: row[col] for col in row.index if col.startswith(('bid_', 'ask_', 'size_'))}\n",
    "                        })\n",
    "\n",
    "                    # Add new raw data to imbalance_df\n",
    "                    if new_raw_rows:\n",
    "                        new_df = pd.DataFrame(new_raw_rows)\n",
    "                        existing_timestamps = set(imbalance_df['timestamp'])\n",
    "                        fresh_rows = new_df[~new_df['timestamp'].isin(existing_timestamps)]\n",
    "\n",
    "                        print(f\"Found {len(fresh_rows)} NEW rows to add (total will be {len(imbalance_df) + len(fresh_rows)})\")\n",
    "\n",
    "                        if not fresh_rows.empty:\n",
    "                            if imbalance_df.empty:\n",
    "                                imbalance_df = fresh_rows.copy()\n",
    "                            else:\n",
    "                                imbalance_df = pd.concat([imbalance_df, fresh_rows], ignore_index=True)\n",
    "\n",
    "                            # Trim to MAX_POINTS\n",
    "                            if len(imbalance_df) > MAX_POINTS:\n",
    "                                imbalance_df = imbalance_df.tail(MAX_POINTS).reset_index(drop=True)\n",
    "\n",
    "                            # RECOMPUTE ALL METRICS ON FULL MAX_POINTS DATA\n",
    "                            print(f\"\\n--- RECOMPUTING METRICS ON {len(imbalance_df)} rows ---\")\n",
    "                            for i in range(len(imbalance_df)):\n",
    "                                row = imbalance_df.iloc[i]\n",
    "                                \n",
    "                                total_bid_n, total_ask_n = compute_notional_totals(row)\n",
    "                                top3_bid_n, top3_ask_n = compute_top3_notional(row)\n",
    "                                \n",
    "                                imbalance_df.loc[i, 'total_bid_notional'] = total_bid_n\n",
    "                                imbalance_df.loc[i, 'total_ask_notional'] = total_ask_n\n",
    "                                imbalance_df.loc[i, 'top3_bid_notional'] = top3_bid_n\n",
    "                                imbalance_df.loc[i, 'top3_ask_notional'] = top3_ask_n\n",
    "                                \n",
    "                                denom = total_bid_n + total_ask_n\n",
    "                                depth_imbalance = (total_bid_n - total_ask_n) / denom if denom != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'depth_imbalance'] = depth_imbalance\n",
    "                                \n",
    "                                ask_bid_walk = top3_ask_n / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'ask_bid_walk'] = ask_bid_walk\n",
    "                                \n",
    "                                ofi_bid, ofi_ask = 0, 0\n",
    "                                if i >= OFI_LOOKBACK:\n",
    "                                    prior_idx = i - OFI_LOOKBACK\n",
    "                                    prior_bid_n = imbalance_df.loc[prior_idx, 'total_bid_notional']\n",
    "                                    prior_ask_n = imbalance_df.loc[prior_idx, 'total_ask_notional']\n",
    "                                    ofi_bid = total_bid_n - prior_bid_n\n",
    "                                    ofi_ask = total_ask_n - prior_ask_n\n",
    "                                imbalance_df.loc[i, 'OFI_bid'] = ofi_bid\n",
    "                                imbalance_df.loc[i, 'OFI_ask'] = ofi_ask\n",
    "                                \n",
    "                                flow_bid = ofi_bid / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                flow_ask = ofi_ask / top3_ask_n if top3_ask_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'flow_bid'] = flow_bid\n",
    "                                imbalance_df.loc[i, 'flow_ask'] = flow_ask\n",
    "\n",
    "                            latest = imbalance_df.iloc[-1]\n",
    "                            print(f\"[{latest['timestamp']}] Imb:{latest['depth_imbalance']:.3f} W:{latest['ask_bid_walk']:.2f} \"\n",
    "                                  f\"OFI_B:${latest['OFI_bid']:,.0f} OFI_A:${latest['OFI_ask']:,.0f} \"\n",
    "                                  f\"F_B:{latest['flow_bid']:.3f} F_A:{latest['flow_ask']:.3f} \"\n",
    "                                  f\"B1:${latest['bid_price']:.2f}x{int(latest['bid_size'])} \"\n",
    "                                  f\"A1:${latest['ask_price']:.2f}x{int(latest['ask_size'])} \"\n",
    "                                  f\"({len(imbalance_df)} rows)\")\n",
    "\n",
    "                    last_file_size = current_file_size\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Processing error: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Clean CSV not found yet, waiting...\")\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        sleep_time = max(0, POLL_INTERVAL - elapsed)\n",
    "        if sleep_time > 0:\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped by user\")\n",
    "    print(f\"Final DataFrame shape: {imbalance_df.shape}\")\n",
    "    if not imbalance_df.empty:\n",
    "        print(\"\\nLatest 5 rows:\")\n",
    "        print(imbalance_df[['timestamp', 'depth_imbalance', 'ask_bid_walk', 'OFI_bid', 'OFI_ask', \n",
    "                           'flow_bid', 'flow_ask', 'bid_price', 'ask_price']].tail())\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8627968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting depth imbalance + normalized OFI monitor (polling every 1.0s)\n",
      "Source: fidelity_orderbook_clean.csv\n",
      "OFI lookback: 8 rows, MAX_POINTS: 10000\n",
      "Waiting for clean CSV data...\n",
      "Loaded 1158 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 1157 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-08 14:11:55] Imb:0.457 W:1.16 F_B:7.263 F_A:-0.595\n",
      "\n",
      "Stopped by user\n",
      "Saved final snapshot to imbalance_live.pkl\n",
      "\n",
      "Final DataFrame shape: (1157, 59)\n",
      "\n",
      "Latest 10 rows of final data:\n",
      "          timestamp  bid_price  ask_price  bid_size  ask_size  size_b_1  bid_1  ask_1  size_a_1  size_b_2  bid_2  ask_2  size_a_2 size_b_3  bid_3  ask_3 size_a_3 size_b_4  bid_4  ask_4 size_a_4 size_b_5         bid_5         ask_5 size_a_5 size_b_6  bid_6  ask_6 size_a_6 size_b_7  bid_7  ask_7 size_a_7 size_b_8  bid_8  ask_8 size_a_8 size_b_9  bid_9  ask_9 size_a_9 size_b_10  bid_10  ask_10 size_a_10 size_b_11  bid_11  ask_11 size_a_11  total_bid_notional  total_ask_notional  top3_bid_notional  top3_ask_notional  depth_imbalance  ask_bid_walk    OFI_bid    OFI_ask  flow_bid  flow_ask\n",
      "2025-12-08 14:08:16     436.35     436.40     160.0        22     160.0 436.35 436.40        22      40.0 436.34 436.40      60.0       40 436.33 436.40       60        4 436.31 436.41       22        2        436.29        436.43       22      160 436.28 436.43      160        2 436.28 436.45       22        3 436.27 436.47       20      102 436.26 436.48        2        12  436.25  436.49        20        41  436.24  435.50        82           229060.31           178934.14          104722.80           61968.80         0.122860      0.591741 -201357.77 -199296.97 -1.922769 -3.216086\n",
      "2025-12-08 14:08:35     436.31     436.34       3.0        80       3.0 436.31 436.34        80      80.0 436.29 436.34      40.0       40 436.29 436.35       40       22 436.27 436.36       60     40 2 436.26 436.23 436.38 436.41    10 20        2 436.21 436.42       84      200 436.20 436.43      100        2 436.19 436.44        2       15 436.18 436.45       20         2  436.17  436.46         2       NaN     NaN     NaN       NaN           159661.51           186773.48           53663.73           69814.80        -0.078260      1.300968   12743.82   52020.06  0.237475  0.745115\n",
      "2025-12-08 14:08:54     436.16     436.22      80.0        80      80.0 436.16 436.22        80      40.0 436.16 436.23     160.0      280 436.15 436.29      600      960 436.14 436.30        2      6 7 436.12 436.11 436.31 436.32     63 2        2 436.10 436.34        2        5 436.09 436.36        2        2 436.07 436.38        2       10 436.06 436.40       12         3  436.05  436.42         2       NaN     NaN     NaN       NaN           602749.14           376068.80          174461.20          366468.40         0.231586      2.100573  525196.43  258397.73  3.010391  0.705102\n",
      "2025-12-08 14:09:15     436.08     436.14      40.0        62      40.0 436.08 436.14        62      80.0 436.08 436.14      40.0       40 436.04 436.14      200        4 436.01 436.16       20    160 4 436.00 435.99 436.17 436.21     60 1        2 435.97 436.22        2        2 435.95 436.24       12       30 435.94 436.26        2        9 435.93 436.28       11         2  435.91  436.29       400       NaN     NaN     NaN       NaN            91132.47           326732.40           69771.20          131714.28        -0.563818      1.887803 -188572.35  131054.40 -2.702725  0.994990\n",
      "2025-12-08 14:09:34     435.99     436.03      40.0        80      40.0 435.99 436.03        80      40.0 435.97 436.03      40.0      160 435.96 436.03       60       80 435.95 436.11       24       21        435.94        436.12        2        7 435.93 436.14        2       40 435.91 436.16       15        2 435.91 436.18       22        1 435.90 436.20       11        22  435.89  436.21         1         1  435.88  436.22         2           180047.95           112069.33          104632.00           78485.40         0.232710      0.750109   83632.28  -24079.56  0.799299 -0.306803\n",
      "2025-12-08 14:09:51     436.09     436.14      80.0        40      80.0 436.09 436.14        40      40.0 436.06 436.14     120.0      120 436.06 436.17       40        2 436.01 436.26        2      2 9 435.99 435.98 436.28 436.30     12 2        2 435.97 436.32       12       12 435.95 436.34        2        9 435.94 436.35        7        2 435.93 436.36       13         3  435.91  436.38         2       NaN     NaN     NaN       NaN           117735.21           103810.13          104656.80           87229.20         0.062854      0.833479     792.39   11274.81  0.007571  0.129255\n",
      "2025-12-08 14:10:18     436.13     436.18       1.0        21       1.0 436.13 436.18        21      80.0 436.11 436.18      40.0       40 436.10 436.18      160      120 436.10 436.24       43    40 40 436.09 436.09 436.25 436.26     60 2        2 436.05 436.27       20        2 436.03 436.28        2       10 436.02 436.30        2        2 436.01 436.31       20         2  435.99  436.32        11       NaN     NaN     NaN       NaN           112949.29           139150.38           52768.93           96395.78        -0.103931      1.826753   -3993.53   46615.06 -0.075680  0.483580\n",
      "2025-12-08 14:11:18     436.14     436.20     200.0        80     200.0 436.14 436.20        80      80.0 436.14 436.20      60.0       40 436.13 436.21       20       20 436.12 436.28        2   20 160 436.09 436.09 436.28 436.30    120 2        3 436.07 436.31       20        9 436.06 436.32        2        2 436.05 436.33       20       40 436.04 436.34        2        22  436.03  436.35        21       NaN     NaN     NaN       NaN           181425.91            99026.23          139564.40           69792.20         0.293810      0.500072  -45015.42  -45435.93 -0.322542 -0.651017\n",
      "2025-12-08 14:11:37     436.02     436.09      80.0       120      80.0 436.02 436.09       120      40.0 436.02 436.09      60.0       40 436.01 436.09       40      200 436.00 436.12       40        3        435.98        436.16        2        2 435.97 436.18        2        3 435.96 436.20        2        2 435.94 436.22       22        3 435.93 436.24       13         2  435.92  436.26         2         3  435.91  436.28        11           163502.07           132142.16           69762.80           95939.80         0.106073      1.375229  -65558.24  -46791.98 -0.939731 -0.487722\n",
      "2025-12-08 14:11:55     435.81     435.88       6.0        40       6.0 435.81 435.88        40      40.0 435.81 435.88      40.0       40 435.81 435.89       20        2 435.80 435.92      160      160        435.80        435.92       60      600 435.80 435.96        2       80 435.76 435.98        2       50 435.75 436.00        2       11 435.74 436.02        3         2  435.72  436.03        40        26  435.71  436.04        31           431872.14           160855.74           37479.66           43588.20         0.457236      1.162983  272210.63  -25917.74  7.262890 -0.594605\n",
      "\n",
      "Column summary (non-null counts and dtypes):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1157 entries, 0 to 1156\n",
      "Data columns (total 59 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   timestamp           1157 non-null   object \n",
      " 1   bid_price           1157 non-null   float64\n",
      " 2   ask_price           1157 non-null   float64\n",
      " 3   bid_size            1157 non-null   float64\n",
      " 4   ask_size            1157 non-null   int64  \n",
      " 5   size_b_1            1157 non-null   float64\n",
      " 6   bid_1               1157 non-null   float64\n",
      " 7   ask_1               1157 non-null   object \n",
      " 8   size_a_1            1157 non-null   int64  \n",
      " 9   size_b_2            1156 non-null   float64\n",
      " 10  bid_2               1157 non-null   object \n",
      " 11  ask_2               1157 non-null   float64\n",
      " 12  size_a_2            1157 non-null   float64\n",
      " 13  size_b_3            1157 non-null   object \n",
      " 14  bid_3               1157 non-null   object \n",
      " 15  ask_3               1156 non-null   float64\n",
      " 16  size_a_3            1157 non-null   object \n",
      " 17  size_b_4            1157 non-null   object \n",
      " 18  bid_4               1157 non-null   object \n",
      " 19  ask_4               1157 non-null   object \n",
      " 20  size_a_4            1157 non-null   object \n",
      " 21  size_b_5            1157 non-null   object \n",
      " 22  bid_5               1157 non-null   object \n",
      " 23  ask_5               1157 non-null   object \n",
      " 24  size_a_5            1157 non-null   object \n",
      " 25  size_b_6            1157 non-null   object \n",
      " 26  bid_6               1157 non-null   object \n",
      " 27  ask_6               1157 non-null   object \n",
      " 28  size_a_6            1157 non-null   object \n",
      " 29  size_b_7            1157 non-null   object \n",
      " 30  bid_7               1157 non-null   object \n",
      " 31  ask_7               1157 non-null   float64\n",
      " 32  size_a_7            1157 non-null   object \n",
      " 33  size_b_8            1157 non-null   object \n",
      " 34  bid_8               1157 non-null   float64\n",
      " 35  ask_8               1157 non-null   float64\n",
      " 36  size_a_8            1157 non-null   object \n",
      " 37  size_b_9            1157 non-null   object \n",
      " 38  bid_9               1157 non-null   float64\n",
      " 39  ask_9               1157 non-null   float64\n",
      " 40  size_a_9            1157 non-null   object \n",
      " 41  size_b_10           1157 non-null   object \n",
      " 42  bid_10              1157 non-null   float64\n",
      " 43  ask_10              1157 non-null   float64\n",
      " 44  size_a_10           1157 non-null   object \n",
      " 45  size_b_11           350 non-null    object \n",
      " 46  bid_11              350 non-null    float64\n",
      " 47  ask_11              350 non-null    float64\n",
      " 48  size_a_11           350 non-null    object \n",
      " 49  total_bid_notional  1157 non-null   float64\n",
      " 50  total_ask_notional  1157 non-null   float64\n",
      " 51  top3_bid_notional   1157 non-null   float64\n",
      " 52  top3_ask_notional   1157 non-null   float64\n",
      " 53  depth_imbalance     1157 non-null   float64\n",
      " 54  ask_bid_walk        1157 non-null   float64\n",
      " 55  OFI_bid             1157 non-null   float64\n",
      " 56  OFI_ask             1157 non-null   float64\n",
      " 57  flow_bid            1157 non-null   float64\n",
      " 58  flow_ask            1157 non-null   float64\n",
      "dtypes: float64(28), int64(2), object(29)\n",
      "memory usage: 533.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# CONFIGURATION\n",
    "CLEAN_CSV_FILE = \"fidelity_orderbook_clean.csv\"\n",
    "POLL_INTERVAL = 1.0\n",
    "MAX_POINTS = 10000\n",
    "OFI_LOOKBACK = 8\n",
    "PICKLE_FILE = \"imbalance_live.pkl\"  # <---- Added global pickle target\n",
    "\n",
    "print(f\"Starting depth imbalance + normalized OFI monitor (polling every {POLL_INTERVAL}s)\")\n",
    "print(f\"Source: {CLEAN_CSV_FILE}\")\n",
    "print(f\"OFI lookback: {OFI_LOOKBACK} rows, MAX_POINTS: {MAX_POINTS}\")\n",
    "\n",
    "imbalance_df = pd.DataFrame(columns=[\n",
    "    'timestamp', 'depth_imbalance', 'ask_bid_walk',\n",
    "    'OFI_bid', 'OFI_ask', 'flow_bid', 'flow_ask',\n",
    "    'bid_price', 'ask_price', 'bid_size', 'ask_size',\n",
    "    'total_bid_notional', 'total_ask_notional', 'top3_bid_notional', 'top3_ask_notional'\n",
    "])\n",
    "last_file_size = 0\n",
    "\n",
    "\n",
    "def compute_notional_totals(row):\n",
    "    total_bid_notional, total_ask_notional = 0, 0\n",
    "    for lvl in range(1, 11):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            total_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            total_bid_notional += bid_p * bid_s\n",
    "    return total_bid_notional, total_ask_notional\n",
    "\n",
    "\n",
    "def compute_top3_notional(row):\n",
    "    top3_bid_notional, top3_ask_notional = 0, 0\n",
    "    for lvl in range(1, 4):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            top3_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            top3_bid_notional += bid_p * bid_s\n",
    "    return top3_bid_notional, top3_ask_notional\n",
    "\n",
    "\n",
    "print(\"Waiting for clean CSV data...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "\n",
    "        if os.path.exists(CLEAN_CSV_FILE):\n",
    "            current_file_size = os.path.getsize(CLEAN_CSV_FILE)\n",
    "            if current_file_size > last_file_size:\n",
    "                try:\n",
    "                    df_clean = pd.read_csv(CLEAN_CSV_FILE)\n",
    "                    print(f\"Loaded {len(df_clean)} rows from clean CSV\")\n",
    "\n",
    "                    new_rows = df_clean\n",
    "                    new_raw_rows = []\n",
    "                    for _, row in new_rows.iterrows():\n",
    "                        bid_price = pd.to_numeric(row.get('bid_1'), errors='coerce')\n",
    "                        ask_price = pd.to_numeric(row.get('ask_1'), errors='coerce')\n",
    "                        bid_size = pd.to_numeric(row.get('size_b_1'), errors='coerce')\n",
    "                        ask_size = pd.to_numeric(row.get('size_a_1'), errors='coerce')\n",
    "                        if pd.isna(bid_price) or pd.isna(ask_price):\n",
    "                            continue\n",
    "                        new_raw_rows.append({\n",
    "                            'timestamp': row['timestamp'],\n",
    "                            'bid_price': bid_price, 'ask_price': ask_price,\n",
    "                            'bid_size': bid_size, 'ask_size': ask_size,\n",
    "                            **{col: row[col] for col in row.index if col.startswith(('bid_', 'ask_', 'size_'))}\n",
    "                        })\n",
    "\n",
    "                    if new_raw_rows:\n",
    "                        new_df = pd.DataFrame(new_raw_rows)\n",
    "                        existing_timestamps = set(imbalance_df['timestamp'])\n",
    "                        fresh_rows = new_df[~new_df['timestamp'].isin(existing_timestamps)]\n",
    "\n",
    "                        if not fresh_rows.empty:\n",
    "                            if imbalance_df.empty:\n",
    "                                imbalance_df = fresh_rows.copy()\n",
    "                            else:\n",
    "                                imbalance_df = pd.concat([imbalance_df, fresh_rows], ignore_index=True)\n",
    "\n",
    "                            if len(imbalance_df) > MAX_POINTS:\n",
    "                                imbalance_df = imbalance_df.tail(MAX_POINTS).reset_index(drop=True)\n",
    "\n",
    "                            print(f\"\\n--- RECOMPUTING METRICS ON {len(imbalance_df)} rows ---\")\n",
    "                            for i in range(len(imbalance_df)):\n",
    "                                row = imbalance_df.iloc[i]\n",
    "                                total_bid_n, total_ask_n = compute_notional_totals(row)\n",
    "                                top3_bid_n, top3_ask_n = compute_top3_notional(row)\n",
    "\n",
    "                                imbalance_df.loc[i, 'total_bid_notional'] = total_bid_n\n",
    "                                imbalance_df.loc[i, 'total_ask_notional'] = total_ask_n\n",
    "                                imbalance_df.loc[i, 'top3_bid_notional'] = top3_bid_n\n",
    "                                imbalance_df.loc[i, 'top3_ask_notional'] = top3_ask_n\n",
    "\n",
    "                                denom = total_bid_n + total_ask_n\n",
    "                                imb = (total_bid_n - total_ask_n) / denom if denom != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'depth_imbalance'] = imb\n",
    "\n",
    "                                ask_bid_walk = top3_ask_n / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'ask_bid_walk'] = ask_bid_walk\n",
    "\n",
    "                                ofi_bid, ofi_ask = 0, 0\n",
    "                                if i >= OFI_LOOKBACK:\n",
    "                                    p_idx = i - OFI_LOOKBACK\n",
    "                                    prior_bid_n = imbalance_df.loc[p_idx, 'total_bid_notional']\n",
    "                                    prior_ask_n = imbalance_df.loc[p_idx, 'total_ask_notional']\n",
    "                                    ofi_bid = total_bid_n - prior_bid_n\n",
    "                                    ofi_ask = total_ask_n - prior_ask_n\n",
    "                                imbalance_df.loc[i, 'OFI_bid'] = ofi_bid\n",
    "                                imbalance_df.loc[i, 'OFI_ask'] = ofi_ask\n",
    "\n",
    "                                flow_bid = ofi_bid / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                flow_ask = ofi_ask / top3_ask_n if top3_ask_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'flow_bid'] = flow_bid\n",
    "                                imbalance_df.loc[i, 'flow_ask'] = flow_ask\n",
    "\n",
    "                            # Save to pickle for other kernels\n",
    "                            imbalance_df.to_pickle(PICKLE_FILE)\n",
    "                            print(f\"Updated pickle: {PICKLE_FILE}\")\n",
    "\n",
    "                            latest = imbalance_df.iloc[-1]\n",
    "                            print(f\"[{latest['timestamp']}] Imb:{latest['depth_imbalance']:.3f} \"\n",
    "                                  f\"W:{latest['ask_bid_walk']:.2f} F_B:{latest['flow_bid']:.3f} F_A:{latest['flow_ask']:.3f}\")\n",
    "\n",
    "                    last_file_size = current_file_size\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Processing error: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Clean CSV not found yet, waiting...\")\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        time.sleep(max(0, POLL_INTERVAL - elapsed))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped by user\")\n",
    "\n",
    "    if not imbalance_df.empty:\n",
    "        # Save final snapshot\n",
    "        imbalance_df.to_pickle(PICKLE_FILE)\n",
    "        print(f\"Saved final snapshot to {PICKLE_FILE}\")\n",
    "        \n",
    "        # Print final dataframe info\n",
    "        print(f\"\\nFinal DataFrame shape: {imbalance_df.shape}\")\n",
    "        print(\"\\nLatest 10 rows of final data:\")\n",
    "        print(imbalance_df.tail(10).to_string(index=False))\n",
    "\n",
    "        # Optional: print data summary\n",
    "        print(\"\\nColumn summary (non-null counts and dtypes):\")\n",
    "        print(imbalance_df.info())\n",
    "    else:\n",
    "        print(\"No data captured — imbalance_df is empty.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
