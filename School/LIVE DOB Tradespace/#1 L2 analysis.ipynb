{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f3b748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting depth imbalance + normalized OFI monitor (polling every 1.0s)\n",
      "Source: fidelity_orderbook_clean.csv\n",
      "OFI lookback: 8 rows, MAX_POINTS: 10000\n",
      "Waiting for clean CSV data...\n",
      "Loaded 533 rows from clean CSV\n",
      "Found 532 NEW rows to add (total will be 532)\n",
      "\n",
      "--- RECOMPUTING METRICS ON 532 rows ---\n",
      "[2025-12-06 12:18:41] Imb:-0.655 W:50.11 OFI_B:$0 OFI_A:$0 F_B:0.000 F_A:0.000 B1:$454.61x1 A1:$454.64x160 (532 rows)\n",
      "\n",
      "Stopped by user\n",
      "Final DataFrame shape: (532, 59)\n",
      "\n",
      "Latest 5 rows:\n",
      "               timestamp  depth_imbalance  ask_bid_walk  OFI_bid  OFI_ask  \\\n",
      "527  2025-12-06 11:57:03        -0.654939     50.110598      0.0      0.0   \n",
      "528  2025-12-06 12:18:17        -0.654939     50.110598      0.0      0.0   \n",
      "529  2025-12-06 12:18:24        -0.654939     50.110598      0.0      0.0   \n",
      "530  2025-12-06 12:18:32        -0.654939     50.110598      0.0      0.0   \n",
      "531  2025-12-06 12:18:41        -0.654939     50.110598      0.0      0.0   \n",
      "\n",
      "     flow_bid  flow_ask  bid_price  ask_price  \n",
      "527       0.0       0.0     454.61     454.64  \n",
      "528       0.0       0.0     454.61     454.64  \n",
      "529       0.0       0.0     454.61     454.64  \n",
      "530       0.0       0.0     454.61     454.64  \n",
      "531       0.0       0.0     454.61     454.64  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# CONFIGURATION\n",
    "CLEAN_CSV_FILE = \"fidelity_orderbook_clean.csv\"\n",
    "POLL_INTERVAL = 1.0\n",
    "MAX_POINTS = 10000\n",
    "OFI_LOOKBACK = 8\n",
    "\n",
    "print(f\"Starting depth imbalance + normalized OFI monitor (polling every {POLL_INTERVAL}s)\")\n",
    "print(f\"Source: {CLEAN_CSV_FILE}\")\n",
    "print(f\"OFI lookback: {OFI_LOOKBACK} rows, MAX_POINTS: {MAX_POINTS}\")\n",
    "\n",
    "imbalance_df = pd.DataFrame(columns=[\n",
    "    'timestamp', 'depth_imbalance', 'ask_bid_walk',\n",
    "    'OFI_bid', 'OFI_ask', 'flow_bid', 'flow_ask',\n",
    "    'bid_price', 'ask_price', 'bid_size', 'ask_size',\n",
    "    'total_bid_notional', 'total_ask_notional', 'top3_bid_notional', 'top3_ask_notional'\n",
    "])\n",
    "last_file_size = 0\n",
    "\n",
    "def compute_notional_totals(row):\n",
    "    \"\"\"Compute total bid/ask notional for a single row (10 levels)\"\"\"\n",
    "    total_bid_notional = 0\n",
    "    total_ask_notional = 0\n",
    "    \n",
    "    for lvl in range(1, 11):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        \n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            total_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            total_bid_notional += bid_p * bid_s\n",
    "    \n",
    "    return total_bid_notional, total_ask_notional\n",
    "\n",
    "def compute_top3_notional(row):\n",
    "    \"\"\"Compute top-3 bid/ask notional for normalization\"\"\"\n",
    "    top3_bid_notional = 0\n",
    "    top3_ask_notional = 0\n",
    "    \n",
    "    for lvl in range(1, 4):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        \n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            top3_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            top3_bid_notional += bid_p * bid_s\n",
    "    \n",
    "    return top3_bid_notional, top3_ask_notional\n",
    "\n",
    "print(\"Waiting for clean CSV data...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "\n",
    "        if os.path.exists(CLEAN_CSV_FILE):\n",
    "            current_file_size = os.path.getsize(CLEAN_CSV_FILE)\n",
    "\n",
    "            if current_file_size > last_file_size:\n",
    "                try:\n",
    "                    df_clean = pd.read_csv(CLEAN_CSV_FILE)\n",
    "                    print(f\"Loaded {len(df_clean)} rows from clean CSV\")\n",
    "\n",
    "                    # *** FIXED: Process ALL rows, not just tail(10) ***\n",
    "                    new_rows = df_clean  # ← ALL ROWS!\n",
    "                    new_raw_rows = []\n",
    "\n",
    "                    for _, row in new_rows.iterrows():\n",
    "                        bid_price = pd.to_numeric(row.get('bid_1'), errors='coerce')\n",
    "                        ask_price = pd.to_numeric(row.get('ask_1'), errors='coerce')\n",
    "                        bid_size = pd.to_numeric(row.get('size_b_1'), errors='coerce')\n",
    "                        ask_size = pd.to_numeric(row.get('size_a_1'), errors='coerce')\n",
    "                        \n",
    "                        if pd.isna(bid_price) or pd.isna(ask_price):\n",
    "                            continue\n",
    "                            \n",
    "                        new_raw_rows.append({\n",
    "                            'timestamp': row['timestamp'],\n",
    "                            'bid_price': bid_price, 'ask_price': ask_price,\n",
    "                            'bid_size': bid_size, 'ask_size': ask_size,\n",
    "                            **{col: row[col] for col in row.index if col.startswith(('bid_', 'ask_', 'size_'))}\n",
    "                        })\n",
    "\n",
    "                    # Add new raw data to imbalance_df\n",
    "                    if new_raw_rows:\n",
    "                        new_df = pd.DataFrame(new_raw_rows)\n",
    "                        existing_timestamps = set(imbalance_df['timestamp'])\n",
    "                        fresh_rows = new_df[~new_df['timestamp'].isin(existing_timestamps)]\n",
    "\n",
    "                        print(f\"Found {len(fresh_rows)} NEW rows to add (total will be {len(imbalance_df) + len(fresh_rows)})\")\n",
    "\n",
    "                        if not fresh_rows.empty:\n",
    "                            if imbalance_df.empty:\n",
    "                                imbalance_df = fresh_rows.copy()\n",
    "                            else:\n",
    "                                imbalance_df = pd.concat([imbalance_df, fresh_rows], ignore_index=True)\n",
    "\n",
    "                            # Trim to MAX_POINTS\n",
    "                            if len(imbalance_df) > MAX_POINTS:\n",
    "                                imbalance_df = imbalance_df.tail(MAX_POINTS).reset_index(drop=True)\n",
    "\n",
    "                            # RECOMPUTE ALL METRICS ON FULL MAX_POINTS DATA\n",
    "                            print(f\"\\n--- RECOMPUTING METRICS ON {len(imbalance_df)} rows ---\")\n",
    "                            for i in range(len(imbalance_df)):\n",
    "                                row = imbalance_df.iloc[i]\n",
    "                                \n",
    "                                total_bid_n, total_ask_n = compute_notional_totals(row)\n",
    "                                top3_bid_n, top3_ask_n = compute_top3_notional(row)\n",
    "                                \n",
    "                                imbalance_df.loc[i, 'total_bid_notional'] = total_bid_n\n",
    "                                imbalance_df.loc[i, 'total_ask_notional'] = total_ask_n\n",
    "                                imbalance_df.loc[i, 'top3_bid_notional'] = top3_bid_n\n",
    "                                imbalance_df.loc[i, 'top3_ask_notional'] = top3_ask_n\n",
    "                                \n",
    "                                denom = total_bid_n + total_ask_n\n",
    "                                depth_imbalance = (total_bid_n - total_ask_n) / denom if denom != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'depth_imbalance'] = depth_imbalance\n",
    "                                \n",
    "                                ask_bid_walk = top3_ask_n / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'ask_bid_walk'] = ask_bid_walk\n",
    "                                \n",
    "                                ofi_bid, ofi_ask = 0, 0\n",
    "                                if i >= OFI_LOOKBACK:\n",
    "                                    prior_idx = i - OFI_LOOKBACK\n",
    "                                    prior_bid_n = imbalance_df.loc[prior_idx, 'total_bid_notional']\n",
    "                                    prior_ask_n = imbalance_df.loc[prior_idx, 'total_ask_notional']\n",
    "                                    ofi_bid = total_bid_n - prior_bid_n\n",
    "                                    ofi_ask = total_ask_n - prior_ask_n\n",
    "                                imbalance_df.loc[i, 'OFI_bid'] = ofi_bid\n",
    "                                imbalance_df.loc[i, 'OFI_ask'] = ofi_ask\n",
    "                                \n",
    "                                flow_bid = ofi_bid / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                flow_ask = ofi_ask / top3_ask_n if top3_ask_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'flow_bid'] = flow_bid\n",
    "                                imbalance_df.loc[i, 'flow_ask'] = flow_ask\n",
    "\n",
    "                            latest = imbalance_df.iloc[-1]\n",
    "                            print(f\"[{latest['timestamp']}] Imb:{latest['depth_imbalance']:.3f} W:{latest['ask_bid_walk']:.2f} \"\n",
    "                                  f\"OFI_B:${latest['OFI_bid']:,.0f} OFI_A:${latest['OFI_ask']:,.0f} \"\n",
    "                                  f\"F_B:{latest['flow_bid']:.3f} F_A:{latest['flow_ask']:.3f} \"\n",
    "                                  f\"B1:${latest['bid_price']:.2f}x{int(latest['bid_size'])} \"\n",
    "                                  f\"A1:${latest['ask_price']:.2f}x{int(latest['ask_size'])} \"\n",
    "                                  f\"({len(imbalance_df)} rows)\")\n",
    "\n",
    "                    last_file_size = current_file_size\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Processing error: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Clean CSV not found yet, waiting...\")\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        sleep_time = max(0, POLL_INTERVAL - elapsed)\n",
    "        if sleep_time > 0:\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped by user\")\n",
    "    print(f\"Final DataFrame shape: {imbalance_df.shape}\")\n",
    "    if not imbalance_df.empty:\n",
    "        print(\"\\nLatest 5 rows:\")\n",
    "        print(imbalance_df[['timestamp', 'depth_imbalance', 'ask_bid_walk', 'OFI_bid', 'OFI_ask', \n",
    "                           'flow_bid', 'flow_ask', 'bid_price', 'ask_price']].tail())\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8627968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting depth imbalance + normalized OFI monitor (polling every 1.0s)\n",
      "Source: fidelity_orderbook_clean.csv\n",
      "OFI lookback: 8 rows, MAX_POINTS: 10000\n",
      "Waiting for clean CSV data...\n",
      "Loaded 1770 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 1763 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-08 16:47:35] Imb:-0.673 W:3.00 F_B:-2.433 F_A:0.930\n",
      "Loaded 1771 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 1764 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-08 16:47:44] Imb:-0.624 W:3.74 F_B:-2.609 F_A:1.505\n",
      "Loaded 1772 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 1765 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-08 16:47:53] Imb:-0.622 W:4.99 F_B:-4.198 F_A:1.527\n",
      "Loaded 1773 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 1766 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-08 16:48:02] Imb:-0.390 W:1.09 F_B:-3.023 F_A:-0.959\n",
      "Loaded 1774 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 1767 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-08 16:48:11] Imb:-0.702 W:6.36 F_B:-8.193 F_A:0.973\n",
      "Loaded 1775 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 1768 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-08 16:48:21] Imb:-0.695 W:5.60 F_B:-6.920 F_A:0.830\n",
      "Loaded 1776 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 1769 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-08 16:48:30] Imb:-0.528 W:3.45 F_B:-2.704 F_A:-0.181\n",
      "Loaded 1777 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 1770 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-08 16:48:39] Imb:-0.505 W:9.15 F_B:-6.639 F_A:-0.326\n",
      "Loaded 1778 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 1771 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-08 16:48:48] Imb:-0.751 W:6.86 F_B:-2.000 F_A:-0.828\n",
      "Loaded 1779 rows from clean CSV\n",
      "\n",
      "--- RECOMPUTING METRICS ON 1772 rows ---\n",
      "Updated pickle: imbalance_live.pkl\n",
      "[2025-12-08 16:48:58] Imb:-0.660 W:9.00 F_B:-2.000 F_A:-0.694\n",
      "\n",
      "Stopped by user\n",
      "Saved final snapshot to imbalance_live.pkl\n",
      "\n",
      "Final DataFrame shape: (1772, 59)\n",
      "\n",
      "Latest 10 rows of final data:\n",
      "          timestamp  bid_price  ask_price  bid_size  ask_size size_b_1  bid_1  ask_1 size_a_1 size_b_2  bid_2  ask_2 size_a_2 size_b_3  bid_3  ask_3 size_a_3 size_b_4         bid_4         ask_4 size_a_4 size_b_5  bid_5  ask_5 size_a_5 size_b_6  bid_6  ask_6 size_a_6 size_b_7  bid_7  ask_7 size_a_7 size_b_8  bid_8  ask_8 size_a_8 size_b_9  bid_9  ask_9 size_a_9 size_b_10  bid_10  ask_10 size_a_10 size_b_11  bid_11  ask_11 size_a_11  total_bid_notional  total_ask_notional  top3_bid_notional  top3_ask_notional  depth_imbalance  ask_bid_walk    OFI_bid    OFI_ask  flow_bid  flow_ask\n",
      "2025-12-08 16:47:35     440.02     440.05      80.0     142.0       80 440.02 440.05      142        1 440.01 440.08      100      120 440.00 440.08      360       99        440.00        440.10      138      120 440.00 440.10      520        4 439.99 440.20        8        5 439.98 440.20      160        2 439.96 440.22       12        7 439.95 440.25      801         1  439.94  440.28         2       NaN     NaN     NaN       NaN           193160.98           987266.75           88441.61          264923.90        -0.672727      2.995467 -215155.64  246373.85 -2.432742  0.929980\n",
      "2025-12-08 16:47:44     440.02     440.05      80.0     142.0       80 440.02 440.05      142       80 440.02 440.08      100        1 440.01 440.08      360       99        440.00        440.10      138      240 440.00 440.10      520        4 439.99 440.20        8        5 439.98 440.20      160        2 439.96 440.22       12        7 439.95 440.25      801         1  439.94  440.28         2       NaN     NaN     NaN       NaN           228362.58           987266.75           70843.21          264923.90        -0.624289      3.739581 -184795.49  398711.16 -2.608514  1.505003\n",
      "2025-12-08 16:47:53     440.02     440.05      40.0     144.0       40 440.02 440.05      144       80 440.02 440.08      100        1 440.01 440.08      360      104        440.00        440.10      138      280 440.00 440.10      520        4 439.99 440.20        8        5 439.98 440.20      160        2 439.96 440.22       12        7 439.95 440.25      801         1  439.94  440.28         2       NaN     NaN     NaN       NaN           230561.78           988146.85           53242.41          265804.00        -0.621629      4.992336 -223523.89  405754.10 -4.198230  1.526516\n",
      "2025-12-08 16:48:02     440.02     440.03      40.0     116.0     40.0 440.02 440.03    116.0     80.0 440.02 440.04     20.0      7.0 440.02 440.05      2.0      1.0        440.01        440.08    100.0    280.0  440.0 440.08    360.0    104.0  440.0 440.09    100.0      4.0 439.99 440.10    138.0      4.0 439.98 440.10    200.0      2.0 439.96 440.20      8.0       7.0  439.95  440.20     160.0       NaN     NaN     NaN       NaN           232762.00           529877.58           55882.54           60724.38        -0.389588      1.086643 -168957.72  -58240.61 -3.023444 -0.959098\n",
      "2025-12-08 16:48:11     440.03     440.08      40.0     100.0       40 440.03 440.08      100       40 440.02 440.08      360        8 440.02 440.09      100        2        440.01        440.10      138      104 440.00 440.10      200      120 440.00 440.20        8        4 439.99 440.20      160        4 439.98 440.22       12        2 439.96 440.25      801         6  439.95  440.28         2       NaN     NaN     NaN       NaN           145201.68           827956.65           38722.16          246445.80        -0.701587      6.364464 -317236.34  239838.46 -8.192630  0.973189\n",
      "2025-12-08 16:48:21     440.02     440.08      40.0     100.0       40 440.02 440.08      100       58 440.02 440.08      360        2 440.01 440.09      100      120         440.0         440.1      138      102  440.0  440.1      200        4 439.99  440.2        8        4 439.98 440.20      160        2 439.96 440.22       12        6 439.95 440.25      801       NaN     NaN     NaN       NaN       NaN     NaN     NaN       NaN           148721.48           827076.09           44001.98          246445.80        -0.695180      5.600789 -304477.99  204635.98 -6.919643  0.830349\n",
      "2025-12-08 16:48:30     440.02     440.08      58.0     320.0       58 440.02 440.08      320        2 440.01 440.09      100      102  440.0  440.1      138      240         440.0         440.1      200      120  440.0  440.2        8        4 439.99  440.2      160        4 439.98 440.22       12        2 439.96 440.25      801        6 439.95 440.28        2       NaN     NaN     NaN       NaN       NaN     NaN     NaN       NaN           236720.68           766345.45           71281.18          245568.40        -0.528006      3.445066 -192717.20  -44428.21 -2.703620 -0.180920\n",
      "2025-12-08 16:48:39     440.03     440.08       1.0     320.0        1 440.03 440.08      320       58 440.02 440.09      100        2 440.01  440.1      138      102         440.0         440.1      200      280  440.0  440.2        8      120  440.0  440.2      160        4 439.99 440.22       12        4 439.98 440.25      801        2 439.96 440.28        2       NaN     NaN     NaN       NaN       NaN     NaN     NaN       NaN           252121.01           766345.45           26841.21          245568.40        -0.504901      9.148932 -178198.61  -80096.50 -6.638993 -0.326168\n",
      "2025-12-08 16:48:48     440.03     440.08      40.0      93.0       40 440.03 440.08       93       59 440.02 440.08      320        2 440.01 440.08      280  103 320 440.00 440.00 440.10 440.20    138 8      120 440.00 440.20      160        4 439.99 440.22       12        4 439.98 440.25      801        2 439.96 440.28        2        6 439.95 440.30        1       NaN     NaN     NaN       NaN       NaN     NaN     NaN       NaN           104281.90           734651.19           44442.40          304975.44        -0.751394      6.862263  -88879.08 -252615.56 -1.999871 -0.828314\n",
      "2025-12-08 16:48:58     440.02     440.08      40.0     320.0       40 440.02 440.08      320       40 440.02 440.08      280        2 440.01  440.1      138      160         440.0        440.15       10       97  440.0  440.2        8        4 439.99  440.2      160        4 439.98 440.22       12        2 439.96 440.25      801        6 439.95 440.28        2       NaN     NaN     NaN       NaN       NaN     NaN     NaN       NaN           156201.12           761940.35           36081.62          324781.80        -0.659745      9.001309  -72161.46 -225326.40 -1.999951 -0.693778\n",
      "\n",
      "Column summary (non-null counts and dtypes):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1772 entries, 0 to 1771\n",
      "Data columns (total 59 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   timestamp           1772 non-null   object \n",
      " 1   bid_price           1772 non-null   float64\n",
      " 2   ask_price           1772 non-null   float64\n",
      " 3   bid_size            1772 non-null   float64\n",
      " 4   ask_size            1771 non-null   float64\n",
      " 5   size_b_1            1772 non-null   object \n",
      " 6   bid_1               1772 non-null   object \n",
      " 7   ask_1               1772 non-null   object \n",
      " 8   size_a_1            1772 non-null   object \n",
      " 9   size_b_2            1769 non-null   object \n",
      " 10  bid_2               1770 non-null   object \n",
      " 11  ask_2               1771 non-null   object \n",
      " 12  size_a_2            1770 non-null   object \n",
      " 13  size_b_3            1771 non-null   object \n",
      " 14  bid_3               1771 non-null   object \n",
      " 15  ask_3               1769 non-null   object \n",
      " 16  size_a_3            1772 non-null   object \n",
      " 17  size_b_4            1772 non-null   object \n",
      " 18  bid_4               1772 non-null   object \n",
      " 19  ask_4               1772 non-null   object \n",
      " 20  size_a_4            1772 non-null   object \n",
      " 21  size_b_5            1772 non-null   object \n",
      " 22  bid_5               1772 non-null   object \n",
      " 23  ask_5               1772 non-null   object \n",
      " 24  size_a_5            1772 non-null   object \n",
      " 25  size_b_6            1772 non-null   object \n",
      " 26  bid_6               1772 non-null   object \n",
      " 27  ask_6               1772 non-null   object \n",
      " 28  size_a_6            1772 non-null   object \n",
      " 29  size_b_7            1772 non-null   object \n",
      " 30  bid_7               1772 non-null   object \n",
      " 31  ask_7               1772 non-null   float64\n",
      " 32  size_a_7            1772 non-null   object \n",
      " 33  size_b_8            1772 non-null   object \n",
      " 34  bid_8               1772 non-null   float64\n",
      " 35  ask_8               1772 non-null   float64\n",
      " 36  size_a_8            1772 non-null   object \n",
      " 37  size_b_9            1758 non-null   object \n",
      " 38  bid_9               1758 non-null   float64\n",
      " 39  ask_9               1758 non-null   float64\n",
      " 40  size_a_9            1758 non-null   object \n",
      " 41  size_b_10           1602 non-null   object \n",
      " 42  bid_10              1602 non-null   float64\n",
      " 43  ask_10              1602 non-null   float64\n",
      " 44  size_a_10           1602 non-null   object \n",
      " 45  size_b_11           378 non-null    object \n",
      " 46  bid_11              381 non-null    float64\n",
      " 47  ask_11              380 non-null    float64\n",
      " 48  size_a_11           376 non-null    object \n",
      " 49  total_bid_notional  1772 non-null   float64\n",
      " 50  total_ask_notional  1772 non-null   float64\n",
      " 51  top3_bid_notional   1772 non-null   float64\n",
      " 52  top3_ask_notional   1772 non-null   float64\n",
      " 53  depth_imbalance     1772 non-null   float64\n",
      " 54  ask_bid_walk        1772 non-null   float64\n",
      " 55  OFI_bid             1772 non-null   float64\n",
      " 56  OFI_ask             1772 non-null   float64\n",
      " 57  flow_bid            1772 non-null   float64\n",
      " 58  flow_ask            1772 non-null   float64\n",
      "dtypes: float64(23), object(36)\n",
      "memory usage: 816.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# CONFIGURATION\n",
    "CLEAN_CSV_FILE = \"fidelity_orderbook_clean.csv\"\n",
    "POLL_INTERVAL = 1.0\n",
    "MAX_POINTS = 10000\n",
    "OFI_LOOKBACK = 8\n",
    "PICKLE_FILE = \"imbalance_live.pkl\"  # <---- Added global pickle target\n",
    "\n",
    "print(f\"Starting depth imbalance + normalized OFI monitor (polling every {POLL_INTERVAL}s)\")\n",
    "print(f\"Source: {CLEAN_CSV_FILE}\")\n",
    "print(f\"OFI lookback: {OFI_LOOKBACK} rows, MAX_POINTS: {MAX_POINTS}\")\n",
    "\n",
    "imbalance_df = pd.DataFrame(columns=[\n",
    "    'timestamp', 'depth_imbalance', 'ask_bid_walk',\n",
    "    'OFI_bid', 'OFI_ask', 'flow_bid', 'flow_ask',\n",
    "    'bid_price', 'ask_price', 'bid_size', 'ask_size',\n",
    "    'total_bid_notional', 'total_ask_notional', 'top3_bid_notional', 'top3_ask_notional'\n",
    "])\n",
    "last_file_size = 0\n",
    "\n",
    "\n",
    "def compute_notional_totals(row):\n",
    "    total_bid_notional, total_ask_notional = 0, 0\n",
    "    for lvl in range(1, 11):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            total_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            total_bid_notional += bid_p * bid_s\n",
    "    return total_bid_notional, total_ask_notional\n",
    "\n",
    "\n",
    "def compute_top3_notional(row):\n",
    "    top3_bid_notional, top3_ask_notional = 0, 0\n",
    "    for lvl in range(1, 4):\n",
    "        ask_p = pd.to_numeric(row.get(f'ask_{lvl}'), errors='coerce')\n",
    "        ask_s = pd.to_numeric(row.get(f'size_a_{lvl}'), errors='coerce')\n",
    "        bid_p = pd.to_numeric(row.get(f'bid_{lvl}'), errors='coerce')\n",
    "        bid_s = pd.to_numeric(row.get(f'size_b_{lvl}'), errors='coerce')\n",
    "        if not (pd.isna(ask_p) or pd.isna(ask_s)):\n",
    "            top3_ask_notional += ask_p * ask_s\n",
    "        if not (pd.isna(bid_p) or pd.isna(bid_s)):\n",
    "            top3_bid_notional += bid_p * bid_s\n",
    "    return top3_bid_notional, top3_ask_notional\n",
    "\n",
    "\n",
    "print(\"Waiting for clean CSV data...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "\n",
    "        if os.path.exists(CLEAN_CSV_FILE):\n",
    "            current_file_size = os.path.getsize(CLEAN_CSV_FILE)\n",
    "            if current_file_size > last_file_size:\n",
    "                try:\n",
    "                    df_clean = pd.read_csv(CLEAN_CSV_FILE)\n",
    "                    print(f\"Loaded {len(df_clean)} rows from clean CSV\")\n",
    "\n",
    "                    new_rows = df_clean\n",
    "                    new_raw_rows = []\n",
    "                    for _, row in new_rows.iterrows():\n",
    "                        bid_price = pd.to_numeric(row.get('bid_1'), errors='coerce')\n",
    "                        ask_price = pd.to_numeric(row.get('ask_1'), errors='coerce')\n",
    "                        bid_size = pd.to_numeric(row.get('size_b_1'), errors='coerce')\n",
    "                        ask_size = pd.to_numeric(row.get('size_a_1'), errors='coerce')\n",
    "                        if pd.isna(bid_price) or pd.isna(ask_price):\n",
    "                            continue\n",
    "                        new_raw_rows.append({\n",
    "                            'timestamp': row['timestamp'],\n",
    "                            'bid_price': bid_price, 'ask_price': ask_price,\n",
    "                            'bid_size': bid_size, 'ask_size': ask_size,\n",
    "                            **{col: row[col] for col in row.index if col.startswith(('bid_', 'ask_', 'size_'))}\n",
    "                        })\n",
    "\n",
    "                    if new_raw_rows:\n",
    "                        new_df = pd.DataFrame(new_raw_rows)\n",
    "                        existing_timestamps = set(imbalance_df['timestamp'])\n",
    "                        fresh_rows = new_df[~new_df['timestamp'].isin(existing_timestamps)]\n",
    "\n",
    "                        if not fresh_rows.empty:\n",
    "                            if imbalance_df.empty:\n",
    "                                imbalance_df = fresh_rows.copy()\n",
    "                            else:\n",
    "                                imbalance_df = pd.concat([imbalance_df, fresh_rows], ignore_index=True)\n",
    "\n",
    "                            if len(imbalance_df) > MAX_POINTS:\n",
    "                                imbalance_df = imbalance_df.tail(MAX_POINTS).reset_index(drop=True)\n",
    "\n",
    "                            print(f\"\\n--- RECOMPUTING METRICS ON {len(imbalance_df)} rows ---\")\n",
    "                            for i in range(len(imbalance_df)):\n",
    "                                row = imbalance_df.iloc[i]\n",
    "                                total_bid_n, total_ask_n = compute_notional_totals(row)\n",
    "                                top3_bid_n, top3_ask_n = compute_top3_notional(row)\n",
    "\n",
    "                                imbalance_df.loc[i, 'total_bid_notional'] = total_bid_n\n",
    "                                imbalance_df.loc[i, 'total_ask_notional'] = total_ask_n\n",
    "                                imbalance_df.loc[i, 'top3_bid_notional'] = top3_bid_n\n",
    "                                imbalance_df.loc[i, 'top3_ask_notional'] = top3_ask_n\n",
    "\n",
    "                                denom = total_bid_n + total_ask_n\n",
    "                                imb = (total_bid_n - total_ask_n) / denom if denom != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'depth_imbalance'] = imb\n",
    "\n",
    "                                ask_bid_walk = top3_ask_n / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'ask_bid_walk'] = ask_bid_walk\n",
    "\n",
    "                                ofi_bid, ofi_ask = 0, 0\n",
    "                                if i >= OFI_LOOKBACK:\n",
    "                                    p_idx = i - OFI_LOOKBACK\n",
    "                                    prior_bid_n = imbalance_df.loc[p_idx, 'total_bid_notional']\n",
    "                                    prior_ask_n = imbalance_df.loc[p_idx, 'total_ask_notional']\n",
    "                                    ofi_bid = total_bid_n - prior_bid_n\n",
    "                                    ofi_ask = total_ask_n - prior_ask_n\n",
    "                                imbalance_df.loc[i, 'OFI_bid'] = ofi_bid\n",
    "                                imbalance_df.loc[i, 'OFI_ask'] = ofi_ask\n",
    "\n",
    "                                flow_bid = ofi_bid / top3_bid_n if top3_bid_n != 0 else np.nan\n",
    "                                flow_ask = ofi_ask / top3_ask_n if top3_ask_n != 0 else np.nan\n",
    "                                imbalance_df.loc[i, 'flow_bid'] = flow_bid\n",
    "                                imbalance_df.loc[i, 'flow_ask'] = flow_ask\n",
    "\n",
    "                            # Save to pickle for other kernels\n",
    "                            imbalance_df.to_pickle(PICKLE_FILE)\n",
    "                            print(f\"Updated pickle: {PICKLE_FILE}\")\n",
    "\n",
    "                            latest = imbalance_df.iloc[-1]\n",
    "                            print(f\"[{latest['timestamp']}] Imb:{latest['depth_imbalance']:.3f} \"\n",
    "                                  f\"W:{latest['ask_bid_walk']:.2f} F_B:{latest['flow_bid']:.3f} F_A:{latest['flow_ask']:.3f}\")\n",
    "\n",
    "                    last_file_size = current_file_size\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Processing error: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Clean CSV not found yet, waiting...\")\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        time.sleep(max(0, POLL_INTERVAL - elapsed))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped by user\")\n",
    "\n",
    "    if not imbalance_df.empty:\n",
    "        # Save final snapshot\n",
    "        imbalance_df.to_pickle(PICKLE_FILE)\n",
    "        print(f\"Saved final snapshot to {PICKLE_FILE}\")\n",
    "        \n",
    "        # Print final dataframe info\n",
    "        print(f\"\\nFinal DataFrame shape: {imbalance_df.shape}\")\n",
    "        print(\"\\nLatest 10 rows of final data:\")\n",
    "        print(imbalance_df.tail(10).to_string(index=False))\n",
    "\n",
    "        # Optional: print data summary\n",
    "        print(\"\\nColumn summary (non-null counts and dtypes):\")\n",
    "        print(imbalance_df.info())\n",
    "    else:\n",
    "        print(\"No data captured — imbalance_df is empty.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
